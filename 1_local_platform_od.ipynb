{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fchNKR2bIUvN"
      },
      "source": [
        "# image_classification_preprocess.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPoXhLvoYhza"
      },
      "outputs": [],
      "source": [
        "# from image_classification_preprocess_sub import exec_process\n",
        "# import logging\n",
        "\n",
        "# def process_for_train(pm):\n",
        "#     exec_process(pm)\n",
        "#     logging.info('[hunmin log] the end line of the function [process_for_train]')\n",
        "\n",
        "\n",
        "# def init_svc(im, rule):\n",
        "#     return {}\n",
        "\n",
        "\n",
        "# def transform(df, params, batch_id):\n",
        "#     logging.info('[hunmin log] df.shape : {}'.format(df.shape))\n",
        "#     logging.info('[hunmin log] type(df) : {}'.format(type(df)))\n",
        "#     logging.info('[hunmin log] the end line of the function [transform]')\n",
        "#     return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHkO7_AMkTJS"
      },
      "source": [
        "# image_classification_preprocess_sub.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBtzb-Y7kYKZ"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import zipfile\n",
        "# import logging\n",
        "\n",
        "# def exec_process(pm):\n",
        "\n",
        "#     logging.info('[hunmin log]  the start line of the function [exec_process]')\n",
        "\n",
        "#     # 저장 파일 확인\n",
        "#     list_files_directories(pm.source_path)\n",
        "\n",
        "#     # pm.source_path의 dataset.zip 파일을\n",
        "#     # pm.target_path 경로에 압축해제\n",
        "#     my_zip_path = os.path.join(pm.source_path,'dataset.zip')\n",
        "#     extract_zip_file = zipfile.ZipFile(my_zip_path)\n",
        "#     extract_zip_file.extractall(pm.target_path)\n",
        "#     extract_zip_file.close()\n",
        "\n",
        "#     # 저장 파일 확인\n",
        "#     list_files_directories(pm.target_path)\n",
        "\n",
        "#     logging.info('[hunmin log]  the finish line of the function [exec_process]')\n",
        "\n",
        "\n",
        "# # 저장 파일 확인\n",
        "# def list_files_directories(path):\n",
        "#     # Get the list of all files and directories in current working directory\n",
        "#     dir_list = os.listdir(path)\n",
        "#     logging.info('[hunmin log] Files and directories in {} :'.format(path))\n",
        "#     logging.info('[hunmin log] dir_list : {}'.format(dir_list))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrtlvZwUZCWD"
      },
      "source": [
        "# train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e790XLElW8Q"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "from train_sub import exec_train\n",
        "import t3qai_client as tc\n",
        "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, T3QAI_TRAIN_DATA_PATH, T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH\n",
        "\n",
        "def main():\n",
        "    result = None\n",
        "    result_msg = \"success\"\n",
        "    a = tc.t3qai_client()\n",
        "    a.train_start()\n",
        "    try:\n",
        "        train()\n",
        "    except Exception as e:\n",
        "        result = e\n",
        "        result_msg = e\n",
        "        logging.info('error log : {}'.format(e))\n",
        "    a.train_finish(result, result_msg)\n",
        "\n",
        "def train():\n",
        "    exec_train()\n",
        "    logging.info('[hunmin log] the end line of the function [train]')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZusgbzKZld-X"
      },
      "source": [
        "# train_sub.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB7GejhKlfua"
      },
      "outputs": [],
      "source": [
        "import t3qai_client as tc\n",
        "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, T3QAI_TRAIN_DATA_PATH, T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH\n",
        "\n",
        "# Imports\n",
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO\n",
        "import psutil\n",
        "\n",
        "# 사용할 gpu 번호를 적는다.\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
        "# 환경 변수 설정 (OpenMP 문제 해결)\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
        "\n",
        "\n",
        "def exec_train():\n",
        "  logging.info('[hunmin log] the start line of the function [exec_train]')\n",
        "  logging.info('[hunmin log] T3QAI_TRAIN_DATA_PATH : {}'.format(T3QAI_TRAIN_DATA_PATH))\n",
        "  \n",
        "  # 저장 파일 확인\n",
        "  list_files_directories(T3QAI_TRAIN_DATA_PATH)\n",
        "  \n",
        "  yaml_path = f\"{T3QAI_TRAIN_DATA_PATH}/dataset.yaml\"\n",
        "\n",
        "  dataset_yaml = f\"\"\"\n",
        "    train: '{T3QAI_TRAIN_DATA_PATH}/dataset/train/images'\n",
        "    val: '{T3QAI_TRAIN_DATA_PATH}/dataset/val/images'\n",
        "\n",
        "    names: ['Road_No_Parking', 'Road_Speed_Limit_in_School_Zone', 'Road_School_Zone', 'Crosswalk',  'Road_No_Stopping_or_Parking',  'Road_No_Stopping_Zone', 'stop', 'traffic_lane_yellow_solid',  'school_zone',  'no_parking',  'fire_hydrant']\n",
        "\n",
        "    train_annotation: '{T3QAI_TRAIN_DATA_PATH}/dataset/train/labels'\n",
        "    val_annotation: '{T3QAI_TRAIN_DATA_PATH}/dataset/val/labels'\n",
        "  \"\"\"\n",
        "\n",
        "  with open(yaml_path, 'w') as file:\n",
        "      file.write(dataset_yaml)\n",
        "  \n",
        "  \n",
        "  ### 데이터 전처리와 학습 모델을 구성하고 모델 학습을 수행\n",
        "  model = YOLO(\"yolov8n.pt\")\n",
        "  # model = YOLO(r\"C:\\Users\\LMK\\Desktop\\output\\best.pt\")\n",
        "\n",
        "  # 시스템 메모리와 CPU 사용량 모니터링\n",
        "  print(f\"CPU usage: {psutil.cpu_percent()}%\")\n",
        "  print(f\"Memory usage: {psutil.virtual_memory().percent}%\")\n",
        "\n",
        "  # 학습 시작\n",
        "  model.train(\n",
        "      data=yaml_path,\n",
        "      epochs=100,\n",
        "      imgsz=640,\n",
        "      batch=32,        # 배치 크기 줄이기\n",
        "      workers=6,      # 워커 수 줄이기\n",
        "      name='yolov8_multiclass',\n",
        "      cache=True,     # 캐시 사용\n",
        "      project= os.path.join(T3QAI_TRAIN_OUTPUT_PATH, 'logs'), # '.\\\\multi_V8\\\\logs',\n",
        "      exist_ok=False\n",
        "  ) \n",
        "  \n",
        "\n",
        "  ### 학습 모델의 성능을 검증하고 배포할 학습 모델을 저장\n",
        "  ### 전처리 객체와 학습 모델 객체를 T3QAI_TRAIN_MODEL_PATH 에 저장\n",
        "  model.export(format=\"onnx\")  # creates 'yolov8n.onnx'\n",
        "\n",
        "  ### 학습 결과를 파일(이미지, 텍스트 등) 형태로 T3QAI_TRAIN_OUTPUT_PATH 에 저장 \n",
        "  \n",
        "  # 모델 로드\n",
        "  model = YOLO(f\"{T3QAI_TRAIN_DATA_PATH}/logs/yolov8_multiclass3/weights/best.pt\")\n",
        "\n",
        "  # 성능 평가 수행\n",
        "  results = model.val(data=yaml_path, conf=0.25, iou=0.5)\n",
        "\n",
        "  # 평가 결과 출력\n",
        "  print(\"Evaluation Results:\")\n",
        "  print(f\"Precision: {results.metrics.precision:.4f}\")\n",
        "  print(f\"Recall: {results.metrics.recall:.4f}\")\n",
        "  print(f\"mAP@0.5: {results.metrics.map50:.4f}\")\n",
        "  print(f\"mAP@0.5:0.95: {results.metrics.map:.4f}\")\n",
        "\n",
        "  # 결과를 파일로 저장\n",
        "  #os.makedirs(T3QAI_TRAIN_OUTPUT_PATH, exist_ok=True)\n",
        "  with open(os.path.join(T3QAI_TRAIN_OUTPUT_PATH, 'evaluation_results.txt'), 'w') as f:\n",
        "      f.write(\"Evaluation Results:\")\n",
        "      f.write(f\"Precision: {results.metrics.precision:.4f}\\n\")\n",
        "      f.write(f\"Recall: {results.metrics.recall:.4f}\\n\")\n",
        "      f.write(f\"mAP@0.5: {results.metrics.map50:.4f}\\n\")\n",
        "      f.write(f\"mAP@0.5:0.95: {results.metrics.map:.4f}\\n\")\n",
        "\n",
        "\n",
        "  # 모델 평가 (Evaluate Model) 및 시각화\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###########################################################################\n",
        "## exec_train() 호출 함수 \n",
        "###########################################################################\n",
        "      \n",
        "# 저장 파일 확인\n",
        "def list_files_directories(path):\n",
        "    # Get the list of all files and directories in current working directory\n",
        "    dir_list = os.listdir(path)\n",
        "    logging.info('[hunmin log] Files and directories in {} :'.format(path))\n",
        "    logging.info('[hunmin log] dir_list : {}'.format(dir_list)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-fhX7WXi0w8"
      },
      "source": [
        "# inference_service.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWSccqAShwME"
      },
      "outputs": [],
      "source": [
        "import t3qai_client as tc\n",
        "from t3qai_client import T3QAI_INIT_MODEL_PATH\n",
        "from inference_service_sub import exec_inference_file # ,exec_init_model\n",
        "\n",
        "import logging\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel('INFO')\n",
        "\n",
        "# def init_model():\n",
        "#   ''' \n",
        "#     - 전처리 객체 불러오기\n",
        "#     - 학습모델 객체 불러오기\n",
        "#       에 필요한 코드 작성 \n",
        "#   '''\n",
        "#   params = exec_init_model()\n",
        "#   logging.info('[hunmin log] the end line of the function [init_model]')\n",
        "#   return { **params }\n",
        "\n",
        "\n",
        "def inference_file(files):\n",
        "  '''\n",
        "    - files 입력에 대한 추론 처리 기능\n",
        "    - 추론시 입력 데이터에 대한 전처리(Data Preprocessing)\n",
        "    - 추론(Inference) 또는 예측(Prediction) \n",
        "    - 추론 결과 데이터 후처리(Data Postprocessing) \n",
        "  '''\n",
        "  result = exec_inference_file(files)\n",
        "  logging.info('[hunmin log] the end line of the function [inference]')\n",
        "  return result\n",
        "\n",
        "\n",
        "# # inference의 return을 DownloadFile 으로 할때 실행합니다.\n",
        "# inference_result = inference_file([\"C:/Users/tjral/Desktop/OD/meta_data/dataset/val/images/891314_614.jpg\"])\n",
        "# print(inference_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zj0ICJWPhaVI"
      },
      "source": [
        "# inference_service_sub.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cz_1gNcujhOv"
      },
      "outputs": [],
      "source": [
        "import logging, os\n",
        "from ultralytics import YOLO\n",
        "from t3qai_client import T3QAI_INIT_MODEL_PATH, T3QAI_TRAIN_MODEL_PATH\n",
        "\n",
        "# def exec_init_model():\n",
        "#   '''init_model에서 사용''''\n",
        "#   model_path = os.path.join(T3QAI_INIT_MODEL_PATH, 'yolov8_multiclass.pt')\n",
        "#   model = YOLO(model_path)\n",
        "#   # model_info_dict = {\n",
        "#   #     \"model\": model\n",
        "#   # }\n",
        "#   return model\n",
        "\n",
        "def extract_labels(results, model_names):\n",
        "      detected_objects = []\n",
        "      for box in results[0].boxes:\n",
        "          cls = int(box.cls[0].item())  # 클래스 번호 추출\n",
        "          conf = box.conf[0].item()  # 신뢰도 값 추출\n",
        "          detected_objects.append((model_names[cls], conf))\n",
        "      return detected_objects\n",
        "\n",
        "def exec_inference_file(files):\n",
        "    \"\"\"\n",
        "    inference_file에서 사용\n",
        "    파일기반 추론함수는 files와 로드한 model을 전달받습니다.\n",
        "    \"\"\"\n",
        "    logging.info('[hunmin log] the start line of the function [exec_inference_file]')\n",
        "\n",
        "    # model_path = os.path.join(T3QAI_INIT_MODEL_PATH, 'best.pt')\n",
        "    \n",
        "    model_path = f\"{T3QAI_TRAIN_MODEL_PATH}/logs/yolov8_multiclass/weights/best.pt\"\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    result = {}\n",
        "    \n",
        "    for idx, one_file in enumerate(files):\n",
        "        logging.info('[hunmin log] file inference')\n",
        "        \n",
        "        inference_file = one_file.file\n",
        "        # image = Image.open(inference_file).convert('L')\n",
        "        # image = image.resize((28, 28))\n",
        "        # image = np.invert(image).astype('float32')/255.\n",
        "        # image = image.reshape(-1, 28, 28 , 1)\n",
        "\n",
        "        logging.info('[hunmin log] load model')\n",
        "        # data predict\n",
        "        \n",
        "        output = model(inference_file)\n",
        "        \n",
        "        if len(output) == 0:\n",
        "          return None, [], None, \"Nothing detected in OD\"\n",
        "\n",
        "        print(model.names)\n",
        "        od_result = extract_labels(output, model.names)\n",
        "        od_result = [label for label, _ in od_result]\n",
        "        \n",
        "        result[f'file{idx}_inference'] = od_result\n",
        "#     result = [DownloadFile(file_path=T3QAI_TRAIN_OUTPUT_PATH+'/Accuracy_Loss.png', file_name='result.jpg'), \n",
        "#               DownloadFile(file_path=T3QAI_TRAIN_OUTPUT_PATH+'/Accuracy_Loss.png', file_name='result2.jpg')]\n",
        "    return result\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iJGX4VFp0Vx"
      },
      "source": [
        "# class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFrJ4Q3QwjV2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import base64\n",
        "import pandas as pd\n",
        "\n",
        "import ipywidgets\n",
        "from ipywidgets import FileUpload\n",
        "from IPython.display import FileLink\n",
        "\n",
        "# t3qai_client 클래스: t3qai_client 객체\n",
        "class t3qai_client:\n",
        "    def train_start(self):\n",
        "        return None\n",
        "\n",
        "    def train_finish(self, result, result_msg):\n",
        "        if result_msg != \"success\":\n",
        "            raise Exception(result_msg)\n",
        "        else:\n",
        "            logging.info(result)\n",
        "            logging.info(\"train finish\")\n",
        "\n",
        "    def train_load_param(self):\n",
        "        '''set_param'''\n",
        "        epoch = 20\n",
        "        batch_size = 16\n",
        "        params = {\"epoch\" : epoch, 'batch_size' : batch_size}\n",
        "        return { **params }\n",
        "\n",
        "class PM:\n",
        "    def __init__(self):\n",
        "        self.source_path = './'\n",
        "        self.target_path = './meta_data'\n",
        "\n",
        "class UploadFile:\n",
        "    def __init__(self, file, filename):\n",
        "        self.file = file\n",
        "        self.filename = filename\n",
        "\n",
        "def DownloadFile(file_name, file_obj = None, file_path = None):\n",
        "    file_route = './meta_data/DownloadFiles'\n",
        "    os.makedirs(file_route, exist_ok = True)\n",
        "    file_dir = os.path.join(file_route, file_name)\n",
        "    if (file_obj == None) == (file_path == None):\n",
        "        Err_msg = \"[DownloadFile Error]: Only one of the 'file_path' or 'file_obj' arguments is required.\"\n",
        "        Err_msg += f\"{0 if file_obj==None else 2} arguments entered.\"\n",
        "        raise Exception(Err_msg)\n",
        "    elif(file_obj != None):\n",
        "        file_obj.seek(0)\n",
        "        file_read = base64.b64encode(file_obj.read()).decode('utf-8')\n",
        "        binary_file = base64.b64decode(file_read)\n",
        "        with open(file_dir, 'wb') as f:\n",
        "            f.write(binary_file)\n",
        "    elif(file_path != None):\n",
        "        shutil.copyfile(file_path, file_dir)\n",
        "\n",
        "    return FileLink(file_dir)\n",
        "\n",
        "pm = PM()\n",
        "\n",
        "T3QAI_TRAIN_OUTPUT_PATH = './meta_data'\n",
        "T3QAI_TRAIN_MODEL_PATH = './meta_data'\n",
        "T3QAI_TRAIN_DATA_PATH = './meta_data'\n",
        "T3QAI_TEST_DATA_PATH = './meta_data'\n",
        "T3QAI_MODULE_PATH = './meta_data'\n",
        "T3QAI_INIT_MODEL_PATH = './meta_data'\n",
        "\n",
        "\n",
        "# t3qai_client 객체\n",
        "tc = t3qai_client()\n",
        "print('T3QAI_TRAIN_OUTPUT_PATH:', T3QAI_TRAIN_OUTPUT_PATH)\n",
        "print('T3QAI_TRAIN_MODEL_PATH:', T3QAI_TRAIN_MODEL_PATH)\n",
        "print('T3QAI_TRAIN_DATA_PATH:', T3QAI_TRAIN_DATA_PATH)\n",
        "print('T3QAI_TEST_DATA_PATH:', T3QAI_TEST_DATA_PATH)\n",
        "print('T3QAI_MODULE_PATH:', T3QAI_MODULE_PATH)\n",
        "print('T3QAI_INIT_MODEL_PATH:', T3QAI_INIT_MODEL_PATH)\n",
        "\n",
        "# init_svc(im, rule) 함수 입력\n",
        "im = None\n",
        "rule = None\n",
        "# transform(df, params, batch_id) 함수 입력\n",
        "batch_id = 0\n",
        "\n",
        "\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "# base64 encoded image - apple.jpg\n",
        "data = [['iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAACySURBVEhL7ZLRDoAgCEWt//9nc8EIEepStvXQeWkyPEKw1FrLbFb+TuWXzichXXb4cAokJR0tH+JFK21G8V6CSqlApMxGelBIsVBHeOOEzZYGdRzpussfL7eIazHPa0wrx0GMdBSiuMbkdINyb5og0gRL3dTbcPtNOpYZveQ2pA1n0hTakF5+hA9Lzd87pNFYLhkvsvT2lMhorndluxkRUuCYbzcp9ROi55+up8sLK1XKBj1wbx3DelAOAAAAAElFTkSuQmCC']]\n",
        "df = pd.DataFrame(data)\n",
        "print('df: ', df)\n",
        "print('df.dtypes:', df.dtypes)\n",
        "\n",
        "# inference_file 함수 추론\n",
        "files = []\n",
        "\n",
        "uploader = FileUpload(accept='*', multiple=True, description='select data', button_style='danger')\n",
        "def uploader_change(change):\n",
        "    uploader.button_style='success'\n",
        "    count = len(uploader.value)\n",
        "    uploader._counter = count\n",
        "    files.clear()\n",
        "    for file_num in range(count):\n",
        "        temp_data = tempfile.TemporaryFile()\n",
        "        if ipywidgets.__version__[0] == '7':\n",
        "            temp_data.write(list(uploader.value.values())[file_num]['content'])\n",
        "            file = UploadFile(temp_data, pd.DataFrame(list(uploader.value.values())[file_num]).iloc[1,0])\n",
        "        elif int(ipywidgets.__version__[0]) > 7:\n",
        "            temp_data.write(uploader.value[file_num].content)\n",
        "            file = UploadFile(temp_data, uploader.value[file_num].name)\n",
        "        files.append(file)\n",
        "\n",
        "uploader.observe(uploader_change, 'value')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyEIDePcwk97"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# process_for_train(pm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxpCm1VTwnxd"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# main() 함수에서 train() 함수 실행\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRzbR0WGyqGQ"
      },
      "outputs": [],
      "source": [
        "# uploader widget(해당 커널 output의 버튼)에 파일을 업로드 한 뒤 infernece_file으로 추론합니다.\n",
        "display(uploader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JUT0RozyrsT"
      },
      "outputs": [],
      "source": [
        "# DataFrame 입력에 대한 추론 결과를 딕셔너리(Dictionary) 형태로 리턴(return)\n",
        "%%time\n",
        "inference_file(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUSc-QRrytTJ"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# inference의 return을 DownloadFile 으로 할때 실행합니다.\n",
        "inference_result = inference_file(files)\n",
        "\n",
        "if type(inference_result) == list:\n",
        "    display(*inference_result)\n",
        "else:\n",
        "    display(inference_result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
