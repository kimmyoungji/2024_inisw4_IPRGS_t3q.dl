{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confident-transcription",
   "metadata": {},
   "source": [
    "# 플랫폼 업로드를 쉽게하기 위한 로컬 개발 코드\n",
    "- T3Q.ai(T3Q.cep + T3Q.dl): 빅데이터/인공지능 통합 플랫폼\n",
    "- 플랫폼 업로드를 쉽게하기 위하여 로컬에서 아래의 코드(파일1)를 개발한다.\n",
    "- 파일 1(파일명): 1_local_platform_image_classification.ipynb\n",
    "\n",
    "### 전처리 객체 또는 학습모델 객체\n",
    "- 전처리 객체나 학습모델 객체는 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "### 데이터셋 (학습 데이터/테스트 데이터)\n",
    "- 학습과 테스트에 사용되는 데이터를 나누어 관리한다.\n",
    "- 학습 데이터: dataset 폴더 아래에 저장하거나 dataset.zip 파일 형태로 저장한다.\n",
    "- 테스트 데이터: test_dataset 폴더 아래에 저장하거나 test_dataset.zip 파일 형태로 저장한다.\n",
    "\n",
    "### 로컬 개발 워크플로우(workflow)  \n",
    "- 로컬 개발 워크플로우를 다음의 4단계로 분리한다.\n",
    "\n",
    "1. 데이터셋 준비(Data Setup)\n",
    "- 로컬 저장소에서 전처리 및 학습에 필요한 학습 데이터셋을 준비한다.\n",
    "\n",
    "2. 데이터 전처리(Data Preprocessing)\n",
    "- 데이터셋의 분석 및 정규화(Normalization)등의 전처리를 수행한다.\n",
    "- 데이터를 모델 학습에 사용할 수 있도록 가공한다.\n",
    "- 추론과정에서 필요한 경우, 데이터 전처리에 사용된 객체를 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "3. 학습 모델 훈련(Train Model)\n",
    "- 데이터를 훈련에 사용할 수 있도록 가공한 뒤에 학습 모델을 구성한다. \n",
    "- 학습 모델을 준비된 데이터셋으로 훈련시킨다.\n",
    "- 정확도(Accuracy)나 손실(Loss)등 학습 모델의 성능을 검증한다.\n",
    "- 학습 모델의 성능 검증 후, 학습 모델을 배포한다.\n",
    "- 배포할 학습 모델을 meta_data 폴더 아래에 저장한다.\n",
    "\n",
    "4. 추론(Inference)\n",
    "- 저장된 전처리 객체나 학습 모델 객체를 준비한다.\n",
    "- 추론에 필요한 테스트 데이터셋을 준비한다.\n",
    "- 배포된 학습 모델을 통해 테스트 데이터에 대한 추론을 진행한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-delight",
   "metadata": {},
   "source": [
    "# 인공지능 통합플랫폼(T3Q.ai) 프로세스를 이해하고 인공지능 쉽게 하기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "median-watershed",
   "metadata": {},
   "source": [
    "1. 머신러닝(Machine Learning)과 딥러닝(Deep Learning) 프로그래밍 패턴\n",
    "\n",
    "(1) 데이터셋 불러오기(Dataset Loading)\n",
    "(2) 데이터 전처리(Data Preprocessing)\n",
    "   - 데이터 정규화(Normalization)\n",
    "   - 학습과 테스트 데이터 분할(Train/Test Data Split) 등\n",
    "(3) 학습 모델 구성(Train Model Build)\n",
    "(4) 학습(Model Training)\n",
    "(5) 학습 모델 성능 검증(Model Performance Validation)\n",
    "(6) 학습 모델 저장(배포) 하기(Model Save)\n",
    "(7) 추론 데이터 전처리((Data Preprocessing)\n",
    "(8) 추론(Inference) 또는 예측(Prediction) \n",
    "(9) 추론 결과 데이터 후처리(Data Postprocessing) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "foster-transcription",
   "metadata": {},
   "source": [
    "2. 빅데이터/인공지능 통합 플랫폼[ T3Q.ai ]에서 딥러닝 프로그래밍 하고 인공지능 서비스 실시간 운용하기\n",
    " - 7개의 함수로 딥러닝 프로그래밍 하고 인공지능 서비스 실시간 운용하기\n",
    "\n",
    "(1) process_for_train(pm) 함수\n",
    " - 데이터셋 준비(Dataset Setup) \n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(2) init_svc(im, rule) 함수\n",
    " - 전처리 객체 불러오기\n",
    "   에 필요한 코드 작성(생략 가능)\n",
    "\n",
    "(3) transform(df, params, batch_id) 함수\n",
    "- 추론 데이터 전처리(Data Preprocessing)\n",
    "  에 필요한 코드 작성(생략 가능)\n",
    "\n",
    "(4) train() 함수 \n",
    " - 데이터셋 불러오기(Dataset Loading)\n",
    " - 데이터 전처리(Data Preprocessing)\n",
    " - 학습 모델 구성(Train Model Build)\n",
    " - 학습(Model Training)\n",
    " - 학습 모델 성능 검증(Model Performance Validation)\n",
    " - 전처리 객체 저장\n",
    " - 학습 모델 저장(배포) 하기\n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(5) init_model() 함수 \n",
    " - 전처리 객체 불러오기\n",
    " - 학습모델 객체 불러오기\n",
    "   에 필요한 코드 작성\n",
    "\n",
    "(6_a) inference_dataframe(df, model_info_dict) 함수\n",
    " - df(pandas DataFrame) 입력에 대한 추론 처리 기능\n",
    " - 추론시 입력 데이터에 대한 전처리(Data Preprocessing)\n",
    " - 추론(Inference) 또는 예측(Prediction) \n",
    " - 추론 결과 데이터 후처리(Data Postprocessing) \n",
    "\n",
    "(6_b) inference_file(files, model_info_dict) 함수\n",
    " - files 입력에 대한 추론 처리 기능\n",
    " - 추론시 입력 데이터에 대한 전처리(Data Preprocessing)\n",
    " - 추론(Inference) 또는 예측(Prediction) \n",
    " - 추론 결과 데이터 후처리(Data Postprocessing) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "naughty-number",
   "metadata": {},
   "source": [
    "3. 전처리 모듈 관리, 학습 알고리즘 관리 함수 설명\n",
    "\n",
    "1) [preprocess.py] 전처리모듈 관리 함수 \n",
    "\n",
    "def process_for_train(pm):\n",
    "    \"\"\"\n",
    "    (1) 입력: pm\n",
    "      # pm.source_path: 학습플랫폼/데이터셋 관리 메뉴에서 저장한 데이터를 불러오는 경로\n",
    "      # pm.target_path: 처리 완료된 데이터를 저장하는 경로\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # 데이터셋 관리 메뉴에서 저장한 데이터를 불러와서 필요한 처리를 수행\n",
    "      # 처리 완료된 데이터를 저장하는 기능, pm.target_path에 저장\n",
    "      # 실행환경 등록에서 General 선택: train() 함수의 T3QAI_TRAIN_DATA_PATH를 통해 데이터를 불러와서 전처리와 학습을 수행 \n",
    "    \"\"\"\n",
    "\n",
    "def init_svc(im, rule):\n",
    "    \"\"\"\n",
    "    (1) 입력: im, rule\n",
    "    (2) 출력: 전처리 객체를 딕셔너리(dictionary) 객체에 담아 리턴(return)\n",
    "    (3) 설명: \n",
    "      # process_for_train(pm) 함수에서 저장한 전처리 객체와 데이터에 적용된 룰(rule)을 불러오는 기능\n",
    "      # 전처리 객체, 룰(rule) 불러오기 기능 없이 처리\n",
    "    \"\"\"\n",
    "\n",
    "    return {}\n",
    "\n",
    "def transform(df, params, batch_id):\n",
    "    \"\"\"\n",
    "    (1) 입력: df, params, batch_id\n",
    "      # df: 추론모델관리와 추론API관리, 실시간 추론을 통해 전달되는 추론 입력 데이터(dataframe 형태)\n",
    "      # params: init_svc(im, rule) 함수의 리턴(return) 값을 params 변수로 전달\n",
    "    (2) 출력: df\n",
    "    (3) 설명: \n",
    "      # df(추론 입력 데이터)에 대한 전처리를 수행한 후 전처리 된 데이터를 inference_dataframe(df, model_info_dict) 함수의 \n",
    "      입력 df에 전달하는 기능\n",
    "      # df(추론 입력 데이터)를 전처리 없이 inference_dataframe(df, model_info_dict) 함수의 입력 df에 리턴(return)\n",
    "    \"\"\"\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "australian-prefix",
   "metadata": {},
   "source": [
    "2-1) [train.py] 학습 알고리즘 관리 함수\n",
    "\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, T3QAI_TRAIN_DATA_PATH\n",
    "\"\"\"\n",
    "(1) 설명:\n",
    "  # t3qai_client : 플랫폼과의 연동을 위한 클라이언트 모듈\n",
    "  # T3QAI_TRAIN_DATA_PATH : pm.target_path에서 저장한 전처리 데이터 경로\n",
    "  # T3QAI_TRAIN_MODEL_PATH : 학습 모델 저장 경로\n",
    "  # T3QAI_TRAIN_OUTPUT_PATH : 학습 결과 출력파일 저장 경로\n",
    "\"\"\"\n",
    "      \n",
    "def train():\n",
    "    \"\"\"\n",
    "    (1) 입력: None\n",
    "    (2) 출력: None\n",
    "    (3) 설명: \n",
    "      # pm.target_path에 저장한 데이터를 T3QAI_TRAIN_DATA_PATH 에서 불러오기\n",
    "      # 데이터 전처리와 학습 모델을 구성하고 모델 학습을 수행\n",
    "      # 학습 모델의 성능을 검증하고 배포할 학습 모델을 저장\n",
    "      # 전처리 객체와 학습 모델 객체를 T3QAI_TRAIN_MODEL_PATH 에 저장\n",
    "      # 학습 결과를 파일(이미지, 텍스트 등) 형태로 T3QAI_TRAIN_OUTPUT_PATH 에 저장 \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "adopted-studio",
   "metadata": {},
   "source": [
    "2-2) [inference_service.py] 학습 알고리즘 관리 함수\n",
    "\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_INIT_MODEL_PATH\n",
    "\"\"\"\n",
    "(1) 설명:\n",
    "  # T3QAI_INIT_MODEL_PATH : train() 함수에서 T3QAI_TRAIN_MODEL_PATH 에 저장한 전처리 객체와 \n",
    "                            학습 모델 객체 등을 추론 하기 위해 불러오는 경로\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def init_model():\n",
    "    \"\"\"\n",
    "    (1) 입력: None\n",
    "    (2) 출력: 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 객체에 담아 리턴(return)\n",
    "    (3) 설명: \n",
    "      # T3QAI_TRAIN_MODEL_PATH에 저장한 전처리 객체와 학습 모델 객체 등을 불러오는 기능\n",
    "      # 전처리 객체와 학습 모델 객체 등을 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "      # 리턴(return) 값을 inference_dataframe(df,model_info_dict), \n",
    "      inference_file(files, model_info_dict) 함수의 입력 model_info_dict 변수로 전달\n",
    "    \"\"\"\n",
    "    return { **params }\n",
    "\n",
    "def inference_dataframe(df, model_info_dict):\n",
    "    \"\"\"\n",
    "    (1) 입력: df, model_info_dict\n",
    "      # df: transform(df, params, batch_id)함수의 리턴(return) 값으로 전달된 df, \n",
    "      추론 입력 데이터(dataframe 형태)\n",
    "      # model_info_dict: init_model() 함수의 return 값을 model_info_dict 변수로 전달\n",
    "        ## 학습 모델 객체 사용 예시       model = model_info_dict.get('model') 또는 \n",
    "                                          model = model_info_dict['model']\n",
    "        ## 전처리(pca) 객체 사용 예시     pca = model_info_dict.get['pca'] 또는\n",
    "                                          pca = model_info_dict['pca']\n",
    "                                          \n",
    "    (2) 출력: 추론 결과 딕셔너리(dictionary) 형태 \n",
    "            result = {'inference': inference_result}\n",
    "\n",
    "                            \n",
    "    (3) 설명: \n",
    "      # 전처리 객체를 사용하여 df(추론 입력 데이터)에 대한 전처리 수행\n",
    "      # 배포된 학습 모델(model)을 사용하여 df(추론 입력 데이터)에 대한 추론(예측)을 수행\n",
    "      # 추론 결과를 딕셔너리(dictionary) 형태로 리턴(return)\n",
    "    \"\"\"\n",
    "    return {**result}\n",
    "\n",
    "def inference_file(files, model_info_dict):\n",
    "    \"\"\"\n",
    "    (1) 입력: files, model_info_dict\n",
    "      # files: 추론 하고자 하는 파일 형태의 입력 \n",
    "      # model_info_dict: init_model() 함수의 return 값을 model_info_dict 변수로 전달\n",
    "        ## 학습 모델 객체 사용 예시       model = model_info_dict.get('model') 또는 \n",
    "                                          model = model_info_dict['model']\n",
    "        ## 전처리(pca) 객체 사용 예시     pca = model_info_dict.get['pca'] 또는\n",
    "                                          pca = model_info_dict['pca']\n",
    "        \n",
    "    (2) 출력: a. 추론 결과 딕셔너리(dictionary) 형태 \n",
    "                  result = {'inference': inference_result}\n",
    "              b. 추론 결과 DownloadFile 형태\n",
    "                  result = DownloadFile(file_path=resultfilepath, file_name=filename1)\n",
    "                  result = DownloadFile(file_obj=resultfileobj, file_name=filename2)\n",
    "              c. 추론 결과 DownloadFile의 list형태\n",
    "                  result = [DownloadFile(file_path=resultfilepath, file_name=filename), \n",
    "                            DownloadFile(file_obj=resultfileobj, file_name=filename), ...]\n",
    "              \n",
    "    (3) 설명: \n",
    "      # 전처리 객체를 사용하여 files(추론 입력 데이터)에 대한 전처리 수행\n",
    "      # 배포된 학습 모델(model)을 사용하여 files(추론 입력 데이터)에 추론(예측)을 수행\n",
    "      # 추론 결과를 a.딕셔너리(dictionary) 형태, b.DownloadFile 형태, c.DownloadFile의 list 형태로 리턴(return)\n",
    "    \"\"\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "structural-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_classification_preprocess.py\n",
    "\n",
    "'''\n",
    "from image_classification_preprocess_sub import exec_process\n",
    "'''\n",
    "\n",
    "import logging\n",
    "\n",
    "def process_for_train(pm):\n",
    "    exec_process(pm)\n",
    "    logging.info('[hunmin log] the end line of the function [process_for_train]')\n",
    "    \n",
    "\n",
    "def init_svc(im, rule):\n",
    "    return {}\n",
    "\n",
    "\n",
    "def transform(df, params, batch_id):\n",
    "    logging.info('[hunmin log] df.shape : {}'.format(df.shape))\n",
    "    logging.info('[hunmin log] type(df) : {}'.format(type(df)))\n",
    "    logging.info('[hunmin log] the end line of the function [transform]')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outdoor-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_classification_preprocess_sub.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import logging\n",
    "\n",
    "\n",
    "def exec_process(pm):\n",
    "    logging.info('[hunmin log] the start line of the function [exec_process]')\n",
    "\n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(pm.source_path)\n",
    "    \n",
    "    # pm.source_path의 dataset.zip 파일을\n",
    "    # pm.target_path 경로에 압축해제\n",
    "    my_zip_path = os.path.join(pm.source_path,'meta_data.zip')\n",
    "    extract_zip_file = zipfile.ZipFile(my_zip_path)\n",
    "    extract_zip_file.extractall(pm.target_path)\n",
    "    extract_zip_file.close()\n",
    "    \n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(pm.target_path)\n",
    "\n",
    "    logging.info('[hunmin log] the finish line of the function [exec_process]')\n",
    "\n",
    "# 저장 파일 확인\n",
    "def list_files_directories(path):\n",
    "    # Get the list of all files and directories in current working directory\n",
    "    dir_list = os.listdir(path)\n",
    "    logging.info('[hunmin log] Files and directories in {} :'.format(path))\n",
    "    logging.info('[hunmin log] dir_list : {}'.format(dir_list))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "guilty-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "import logging, os\n",
    "\"\"\"\n",
    "from train_sub import exec_train\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, \\\n",
    "                            T3QAI_TRAIN_DATA_PATH, T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    result = None\n",
    "    result_msg = \"success\"\n",
    "    tc.train_start()\n",
    "    try:\n",
    "        train()\n",
    "    except Exception as e:\n",
    "        result = e\n",
    "        result_msg = e\n",
    "        logging.info('error log : {}'.format(e))\n",
    "    tc.train_finish(result, result_msg)\n",
    "\n",
    "def train():\n",
    "    exec_train()\n",
    "    logging.info('[hunmin log] the end line of the function [train]')\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chronic-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  train_sub.py\n",
    "\n",
    "\"\"\"\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, \\\n",
    "                            T3QAI_TRAIN_DATA_PATH, T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH\n",
    "\"\"\"\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import utils\n",
    "# from tensorflow.keras import layers\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logging.info(f'[hunmin log] tensorflow ver : {tf.__version__}')\n",
    "\n",
    "# 사용할 gpu 번호를 적는다.\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         tf.config.experimental.set_visible_devices(gpus, 'GPU')\n",
    "#         logging.info('[hunmin log] gpu set complete')\n",
    "#         logging.info('[hunmin log] num of gpu: {}'.format(len(gpus)))\n",
    "    \n",
    "#     except RuntimeError as e:\n",
    "#         logging.info('[hunmin log] gpu set failed')\n",
    "#         logging.info(e)\n",
    "        \n",
    "        \n",
    "def exec_train():\n",
    "    logging.info('[hunmin log] the start line of the function [exec_train]')\n",
    "    logging.info('[hunmin log] T3QAI_TRAIN_DATA_PATH : {}'.format(T3QAI_TRAIN_DATA_PATH))\n",
    "    \n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(T3QAI_TRAIN_DATA_PATH)\n",
    "    my_path = os.path.join(T3QAI_TRAIN_DATA_PATH, 'dataset') + '/'\n",
    "    \n",
    "    # 카테고리\n",
    "    dataset=['ant', 'apple', 'bus', 'butterfly', 'cup', 'envelope', 'fish', 'giraffe', 'lightbulb', 'pig']\n",
    "    dataset_num = len(dataset) #10\n",
    "\n",
    "    # 경로에 있는 numpy를 load하고 dataset_numpy list에 추가한다.\n",
    "    dataset_numpy = []\n",
    "    for i in range (dataset_num):\n",
    "        ad = my_path + str(dataset[i]) + '.npy'\n",
    "        dataset_numpy.append(np.load(ad))\n",
    "    \n",
    "    for i in range (dataset_num):\n",
    "        logging.info('[hunmin log] : {}'.format(dataset_numpy[i].shape))\n",
    "    \n",
    "    np.set_printoptions(linewidth = 116)\n",
    "    # dataset_numpy[5] 가 envelope numpy 이다.\n",
    "    logging.info('[hunmin log] envelope : {}'.format(dataset_numpy[5][0]))\n",
    "\n",
    "    # 카테고리별로 같은 수의 이미지를 훈련시키기 위해 훈련시키고자 하는 이미지의 개수를 정해준다.\n",
    "    idx = 1000\n",
    "    \n",
    "    # 데이터 정규화 (Normalization) & 데이터 합치기 & 레이블 생성\n",
    "    # X: 입력 이미지 배열 데이터\n",
    "    # Y: 정답 레이블 데이터\n",
    "    # 정규화 및 정답 레이블 생성\n",
    "    X = np.array([data_numpy[:idx, :]/255. for data_numpy in dataset_numpy]).astype('float32')\n",
    "    X = X.reshape(-1, 28*28)\n",
    "    Y = np.array([i for i in range(10) for j in range(idx)]).astype('float32')\n",
    "\n",
    "    # 훈련 & 평가 데이터셋 생성\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "    # 모델 훈련에 사용할 수 있는 형태로 변경\n",
    "    # X의 값을 [samples][pixels][width][height] 형태로 reshape한다.\n",
    "    X_train_cnn = X_train.reshape(X_train.shape[0], 28, 28 , 1).astype('float32')\n",
    "    X_test_cnn = X_test.reshape(X_test.shape[0], 28, 28 , 1).astype('float32')\n",
    "    \n",
    "    # reshape된 결과 확인 및 원래 배열의 형태와 비교\n",
    "    logging.info('[hunmin log] X_train : {}'.format(X_train.shape))\n",
    "    logging.info('[hunmin log] X_train_cnn : {}'.format(X_train_cnn.shape))\n",
    "\n",
    "    \n",
    "    # Y의 배열에 one-hot-encoding 진행\n",
    "    Y_train_cnn = utils.to_categorical(Y_train)\n",
    "    Y_test_cnn = utils.to_categorical(Y_test)\n",
    "    num_classes = Y_test_cnn.shape[1] # class는 총 10개이다.\n",
    "\n",
    "    # encoding된 결과 확인 및 원래 배열의 형태와 비교\n",
    "    logging.info('[hunmin log] Y_train : {}'.format(Y_train.shape))\n",
    "    logging.info('[hunmin log] Y_train_cnn : {}'.format(Y_train_cnn.shape))\n",
    "    logging.info('[hunmin log] class number : {}'.format(num_classes))\n",
    "    \n",
    "    # 모델 구축 (Build Model)\n",
    "    # 이미지 분류를 위해 아주 간단한 CNN 모델을 Keras를 이용하여 구축하고자 한다.\n",
    "    \n",
    "    # 단일 gpu 혹은 cpu학습\n",
    "    if len(gpus) < 2:\n",
    "        model = model_build_and_compile(num_classes)\n",
    "    # multi-gpu\n",
    "    else:\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        logging.info('[hunmin log] gpu devices num {}'.format(strategy.num_replicas_in_sync))\n",
    "        with strategy.scope():\n",
    "            model = model_build_and_compile(num_classes)\n",
    "\n",
    "    # 사용자 입력 파라미터\n",
    "    user_params = tc.train_load_param()\n",
    "    batch_size = int(user_params[\"batch_size\"])\n",
    "    epochs = int(user_params[\"epoch\"])\n",
    "\n",
    "    # gpu에 따른 batch_size 설정\n",
    "    batch_size = batch_size * len(gpus) if len(gpus) > 0 else batch_size\n",
    "\n",
    "    # 모델 학습 (Train Model)\n",
    "    history = model.fit(X_train_cnn, Y_train_cnn, \n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs, \n",
    "                        validation_split=0.1, \n",
    "                        verbose=0, \n",
    "                        callbacks=[LossAndErrorPrintingCallback()]\n",
    "                       )\n",
    "    \n",
    "    # 모델 평가 (Evaluate Model)\n",
    "    loss, acc = model.evaluate(X_test_cnn, Y_test_cnn, verbose=0, callbacks=[LossAndErrorPrintingCallback()])\n",
    "\n",
    "    # 로컬 시각화\n",
    "    acc = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "    ax[0].plot(acc, label = 'accuracy')\n",
    "    ax[0].plot(val_acc, label = 'val_accuracy')\n",
    "    ax[0].set_title(\"Accuracy\")\n",
    "    ax[1].plot(loss, label = 'Loss')\n",
    "    ax[1].plot(val_loss, label = 'val_loss')\n",
    "    ax[1].set_title(\"Loss\")\n",
    "    fig.savefig(os.path.join(T3QAI_TRAIN_OUTPUT_PATH, 'Accuracy_Loss.png'))\n",
    "    \n",
    "    logging.info('[hunmin log] loss : {}'.format(loss))\n",
    "    logging.info('[hunmin log] acc : {}'.format(acc))\n",
    "\n",
    "    ###########################################################################\n",
    "    ## 플랫폼 시각화\n",
    "    ###########################################################################\n",
    "    \"\"\"\n",
    "    plot_metrics(tc, history, model, X_test_cnn, Y_test_cnn)\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info('[hunmin log] T3QAI_TRAIN_MODEL_PATH : {}'.format(T3QAI_TRAIN_MODEL_PATH))\n",
    "    model.save(os.path.join(T3QAI_TRAIN_MODEL_PATH, 'cnn_model.h5'))\n",
    "    \n",
    "    # 저장 파일 확인\n",
    "    list_files_directories(T3QAI_TRAIN_MODEL_PATH)\n",
    "    \n",
    "    logging.info('[hunmin log] the finish line of the function [exec_train]')\n",
    "    \n",
    "###########################################################################\n",
    "## exec_train() 호출 함수 \n",
    "###########################################################################\n",
    "# for epoch, loss\n",
    "class LossAndErrorPrintingCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        logging.info('[hunmin log] For epoch {}, loss is {:.2f}.'.format(batch+1, logs['loss']))\n",
    "\n",
    "def model_build_and_compile(num_classes):\n",
    "    #모델 구축\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(28,28,1)),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation=\"relu\"),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation=\"relu\"),\n",
    "            layers.Dropout(0.25),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), padding='same', activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(32, activation=\"relu\"),\n",
    "            layers.Dropout(0.25),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ]\n",
    "    )\n",
    "    logging.info('[hunmin log] model.summary() :')\n",
    "    model.summary(print_fn=logging.info)\n",
    "    \n",
    "    # 모델 컴파일 (Compile Model)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "# 시각화\n",
    "def plot_metrics(tc, history, model, x_test, y_test):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    accuracy_list = history.history['accuracy']\n",
    "    loss_list = history.history['loss']\n",
    "    \n",
    "    for step, (acc, loss) in enumerate(zip(accuracy_list, loss_list)):\n",
    "        metric={}\n",
    "        metric['accuracy'] = acc\n",
    "        metric['loss'] = loss\n",
    "        metric['step'] = step\n",
    "        tc.train_save_stat_metrics(metric)\n",
    "\n",
    "    predict_y = np.argmax(model.predict(x_test), axis = 1).tolist()\n",
    "    actual_y = np.argmax(y_test, axis = 1).tolist()\n",
    "    \n",
    "    eval_results={}\n",
    "    eval_results['predict_y'] = predict_y\n",
    "    eval_results['actual_y'] = actual_y\n",
    "    eval_results['accuracy'] = history.history['val_accuracy'][-1]\n",
    "    eval_results['loss'] = history.history['val_loss'][-1]\n",
    "\n",
    "    # calculate_confusion_matrix(eval_results)\n",
    "    eval_results['confusion_matrix'] = confusion_matrix(actual_y, predict_y).tolist()\n",
    "    tc.train_save_result_metrics(eval_results)\n",
    "    logging.info('[hunmin log] accuracy and loss curve plot for platform')\n",
    "    \n",
    "# 저장 파일 확인\n",
    "def list_files_directories(path):\n",
    "    # Get the list of all files and directories in current working directory\n",
    "    dir_list = os.listdir(path)\n",
    "    logging.info('[hunmin log] Files and directories in {} :'.format(path))\n",
    "    logging.info('[hunmin log] dir_list : {}'.format(dir_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alike-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_service.py\n",
    "\n",
    "\"\"\"\n",
    "from inference_service_sub import exec_init_model, exec_inference_dataframe, exec_inference_file\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "def init_model():\n",
    "    params = exec_init_model()\n",
    "    logging.info('[hunmin log] the end line of the function [init_model]')\n",
    "    return { **params }\n",
    "\n",
    "\n",
    "def inference_dataframe(df, model_info_dict):\n",
    "    result = exec_inference_dataframe(df, model_info_dict)\n",
    "    logging.info('[hunmin log] the end line of the function [inference_dataframe]')\n",
    "    return { **result }\n",
    "\n",
    "\n",
    "def inference_file(files, model_info_dict):\n",
    "    result = exec_inference_file(files, model_info_dict)\n",
    "    logging.info('[hunmin log] the end line of the function [inference_file]')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contained-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_service_sub.py\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import logging\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"\n",
    "from t3qai_client import DownloadFile\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, T3QAI_TRAIN_DATA_PATH, \\\n",
    "                            T3QAI_TEST_DATA_PATH, T3QAI_MODULE_PATH, T3QAI_INIT_MODEL_PATH\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def exec_init_model():\n",
    "    model_path = os.path.join(T3QAI_INIT_MODEL_PATH, 'cnn_model.h5')\n",
    "    model = load_model(model_path)\n",
    "    model_info_dict = {\n",
    "        \"model\": model\n",
    "    }\n",
    "    return model_info_dict\n",
    "\n",
    "def exec_inference_dataframe(df, model_info_dict):\n",
    "    \n",
    "    logging.info('[hunmin log] the start line of the function [exec_inference_dataframe]')\n",
    "    \n",
    "    ## 학습 모델 준비\n",
    "    model = model_info_dict['model']\n",
    "    labels = ['ant', 'apple', 'bus', 'butterfly', 'cup', 'envelope', 'fish', 'giraffe', 'lightbulb', 'pig']\n",
    "    \n",
    "    # image preprocess\n",
    "    img_base64 = df.iloc[0, 0]\n",
    "    image_bytes = io.BytesIO(base64.b64decode(img_base64))\n",
    "    image = Image.open(image_bytes).convert('L')\n",
    "    image = image.resize((28, 28))\n",
    "    image = np.invert(image).astype('float32')/255.\n",
    "    image = image.reshape(-1, 28, 28, 1)\n",
    "    \n",
    "    # data predict\n",
    "    y_pred = model.predict(image, verbose=0)\n",
    "    y_pred_idx = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # inverse transform\n",
    "    result = {'inference' : [labels[y_pred_idx[0]]]}\n",
    "    logging.info('[hunmin log] result : {}'.format(result))\n",
    "\n",
    "    return result\n",
    "\n",
    "def exec_inference_file(files, model_info_dict):\n",
    "    \n",
    "    \"\"\"파일기반 추론함수는 files와 로드한 model을 전달받습니다.\"\"\"\n",
    "    logging.info('[hunmin log] the start line of the function [exec_inference_file]')\n",
    "    model = model_info_dict['model']\n",
    "    labels = ['ant', 'apple', 'bus', 'butterfly', 'cup', 'envelope', 'fish', 'giraffe', 'lightbulb', 'pig']\n",
    "\n",
    "    inference_result = []\n",
    "    \n",
    "    for one_file in files:\n",
    "        logging.info(f'[hunmin log] inference: {one_file.filename}')\n",
    "        inference_file = one_file.file\n",
    "        image = Image.open(inference_file).convert('L')\n",
    "        image = image.resize((28, 28))\n",
    "        image = np.invert(image).astype('float32')/255.\n",
    "        image = image.reshape(-1, 28, 28 , 1)\n",
    "\n",
    "        logging.info(f'[hunmin log] predict: {one_file.filename}')\n",
    "        # data predict\n",
    "        y_pred = model.predict(image, verbose=0)\n",
    "        y_pred_idx = np.argmax(y_pred, axis=1)\n",
    "        \n",
    "        inference_result.append(labels[y_pred_idx[0]])\n",
    "        \n",
    "#     result = [DownloadFile(file_path=T3QAI_TRAIN_OUTPUT_PATH + '/Accuracy_Loss.png', file_name='result.jpg'), \n",
    "#               DownloadFile(file_path=T3QAI_TRAIN_OUTPUT_PATH + '/Accuracy_Loss.png', file_name='result2.jpg')]\n",
    "\n",
    "    result = {'inference' : inference_result}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "drawn-original",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T3QAI_TRAIN_OUTPUT_PATH: ./meta_data\n",
      "T3QAI_TRAIN_MODEL_PATH: ./meta_data\n",
      "T3QAI_TRAIN_DATA_PATH: ./meta_data\n",
      "T3QAI_TEST_DATA_PATH: ./meta_data\n",
      "T3QAI_MODULE_PATH: ./meta_data\n",
      "T3QAI_INIT_MODEL_PATH: ./meta_data\n",
      "df:                                                     0\n",
      "0  iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAA...\n",
      "df.dtypes: 0    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import FileUpload\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# t3qai_client 클래스: t3qai_client 객체\n",
    "class t3qai_client:\n",
    "    def train_start(self):\n",
    "        return None\n",
    "\n",
    "    def train_finish(self, result, result_msg):\n",
    "        if result_msg != \"success\":\n",
    "            raise Exception(result_msg)\n",
    "        else:\n",
    "            logging.info(result)\n",
    "            logging.info(\"train finish\")\n",
    "\n",
    "    def train_load_param(self):\n",
    "        '''set_param'''\n",
    "        epoch = 20\n",
    "        batch_size = 16\n",
    "        params = {\"epoch\" : epoch, 'batch_size' : batch_size}\n",
    "        return { **params }\n",
    "\n",
    "class PM:\n",
    "    def __init__(self):\n",
    "        self.source_path = './'\n",
    "        self.target_path = './meta_data'\n",
    "        \n",
    "class UploadFile:\n",
    "    def __init__(self, file, filename):\n",
    "        self.file = file\n",
    "        self.filename = filename\n",
    "\n",
    "def DownloadFile(file_name, file_obj = None, file_path = None):\n",
    "    file_route = './meta_data/DownloadFiles'\n",
    "    os.makedirs(file_route, exist_ok = True)\n",
    "    file_dir = os.path.join(file_route, file_name)\n",
    "    if (file_obj == None) == (file_path == None):\n",
    "        Err_msg = \"[DownloadFile Error]: Only one of the 'file_path' or 'file_obj' arguments is required.\"\n",
    "        Err_msg += f\"{0 if file_obj==None else 2} arguments entered.\"\n",
    "        raise Exception(Err_msg)\n",
    "    elif(file_obj != None):\n",
    "        file_obj.seek(0)\n",
    "        file_read = base64.b64encode(file_obj.read()).decode('utf-8')\n",
    "        binary_file = base64.b64decode(file_read)\n",
    "        with open(file_dir, 'wb') as f:\n",
    "            f.write(binary_file)\n",
    "    elif(file_path != None):\n",
    "        shutil.copyfile(file_path, file_dir)\n",
    "        \n",
    "    return FileLink(file_dir)\n",
    "\n",
    "pm = PM()\n",
    "\n",
    "T3QAI_TRAIN_OUTPUT_PATH = './meta_data'\n",
    "T3QAI_TRAIN_MODEL_PATH = './meta_data'\n",
    "T3QAI_TRAIN_DATA_PATH = './meta_data'\n",
    "T3QAI_TEST_DATA_PATH = './meta_data'\n",
    "T3QAI_MODULE_PATH = './meta_data'\n",
    "T3QAI_INIT_MODEL_PATH = './meta_data'\n",
    "\n",
    "\n",
    "# t3qai_client 객체\n",
    "tc = t3qai_client()\n",
    "print('T3QAI_TRAIN_OUTPUT_PATH:', T3QAI_TRAIN_OUTPUT_PATH)\n",
    "print('T3QAI_TRAIN_MODEL_PATH:', T3QAI_TRAIN_MODEL_PATH)\n",
    "print('T3QAI_TRAIN_DATA_PATH:', T3QAI_TRAIN_DATA_PATH)\n",
    "print('T3QAI_TEST_DATA_PATH:', T3QAI_TEST_DATA_PATH)\n",
    "print('T3QAI_MODULE_PATH:', T3QAI_MODULE_PATH)\n",
    "print('T3QAI_INIT_MODEL_PATH:', T3QAI_INIT_MODEL_PATH)\n",
    "\n",
    "# init_svc(im, rule) 함수 입력\n",
    "im = None\n",
    "rule = None\n",
    "# transform(df, params, batch_id) 함수 입력\n",
    "batch_id = 0\n",
    "\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# base64 encoded image - apple.jpg\n",
    "data = [['iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAACySURBVEhL7ZLRDoAgCEWt//9nc8EIEepStvXQeWkyPEKw1FrLbFb+TuWXzichXXb4cAokJR0tH+JFK21G8V6CSqlApMxGelBIsVBHeOOEzZYGdRzpussfL7eIazHPa0wrx0GMdBSiuMbkdINyb5og0gRL3dTbcPtNOpYZveQ2pA1n0hTakF5+hA9Lzd87pNFYLhkvsvT2lMhorndluxkRUuCYbzcp9ROi55+up8sLK1XKBj1wbx3DelAOAAAAAElFTkSuQmCC']]\n",
    "df = pd.DataFrame(data)\n",
    "print('df: ', df)\n",
    "print('df.dtypes:', df.dtypes)\n",
    "\n",
    "# inference_file 함수 추론\n",
    "files = []\n",
    "\n",
    "uploader = FileUpload(accept='*', multiple=True, description='select data', button_style='danger')\n",
    "def uploader_change(change):\n",
    "    uploader.button_style='success'\n",
    "    count = len(uploader.value)\n",
    "    uploader._counter = count\n",
    "    files.clear()\n",
    "    for file_num in range(count):\n",
    "        temp_data = tempfile.TemporaryFile()\n",
    "        if ipywidgets.__version__[0] == '7':\n",
    "            temp_data.write(list(uploader.value.values())[file_num]['content'])\n",
    "            file = UploadFile(temp_data, pd.DataFrame(list(uploader.value.values())[file_num]).iloc[1,0])\n",
    "        elif int(ipywidgets.__version__[0]) > 7:\n",
    "            temp_data.write(uploader.value[file_num].content)\n",
    "            file = UploadFile(temp_data, uploader.value[file_num].name)\n",
    "        files.append(file)\n",
    "\n",
    "uploader.observe(uploader_change, 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "powerful-swing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the start line of the function [exec_process]\n",
      "INFO:root:[hunmin log] Files and directories in ./ :\n",
      "INFO:root:[hunmin log] dir_list : ['README.txt', 'dataset.zip', 'T3Q.ai_platform_image_classification', 'meta_data', '2_1_1_platform_image_classification_preprocess.py', '.ipynb_checkpoints', '2_2_2_platform_image_classification_train_sub.py', '0_local_image_classification.ipynb', '1_local_platform_image_classification.ipynb', '0_local_image_classification_requirement.txt', '2_2_1_platform_image_classification_train.py', '2_1_2_platform_image_classification_preprocess_sub.py', 'LICENSE.txt', 'test_dataset.zip', '2_2_3_platform_image_classification_inference_service.py', '2_2_4_platform_image_classification_inference_service_sub.py']\n",
      "INFO:root:[hunmin log] Files and directories in ./meta_data :\n",
      "INFO:root:[hunmin log] dir_list : ['cnn_model.h5', 'dataset', 'test_dataset', 'Accuracy_Loss.png', 'DownloadFiles']\n",
      "INFO:root:[hunmin log] the finish line of the function [exec_process]\n",
      "INFO:root:[hunmin log] the end line of the function [process_for_train]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.69 s, sys: 5.39 s, total: 12.1 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "process_for_train(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assigned-david",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the start line of the function [exec_train]\n",
      "INFO:root:[hunmin log] T3QAI_TRAIN_DATA_PATH : ./meta_data\n",
      "INFO:root:[hunmin log] Files and directories in ./meta_data :\n",
      "INFO:root:[hunmin log] dir_list : ['cnn_model.h5', 'dataset', 'test_dataset', 'Accuracy_Loss.png', 'DownloadFiles']\n",
      "INFO:root:[hunmin log] : (124612, 784)\n",
      "INFO:root:[hunmin log] : (144722, 784)\n",
      "INFO:root:[hunmin log] : (166208, 784)\n",
      "INFO:root:[hunmin log] : (117999, 784)\n",
      "INFO:root:[hunmin log] : (130721, 784)\n",
      "INFO:root:[hunmin log] : (134863, 784)\n",
      "INFO:root:[hunmin log] : (134150, 784)\n",
      "INFO:root:[hunmin log] : (127182, 784)\n",
      "INFO:root:[hunmin log] : (120879, 784)\n",
      "INFO:root:[hunmin log] : (186770, 784)\n",
      "INFO:root:[hunmin log] envelope : [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  11  17  26  34  34  37  51  51  51  66 112 123   1   0\n",
      "   0   0   0   0   0   0   1  29  63  97 132 166 200 235 255 255 255 255 255 255 255 255 255 255 255 255 117   0\n",
      "   0  12  78 138 180 215 248 255 255 255 247 213 179 145 110 102 102  85  85  85  74  68  68  69 215 255 101   0\n",
      "   0 122 255 249 199 164 130  96  61  27   1   0   0   0   0   0   0   0   0   0   0   0   1 164 252 255  94   0\n",
      "   0 120 255 250  59   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 115 255 116 255 113   0\n",
      "   0 116 255 213 230  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  30 245 165   0 255 121   0\n",
      "   0 113 255  44 239 198   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0 171 242  25   3 255 119   0\n",
      "   0 110 255  11  77 253 146   0   0   0   0   0   0   0   0   0   0   0   0   0  66 255 114   0   5 255 116   0\n",
      "   0 107 255  14   0 131 255  97   0   0   0   0   0   0   0   0   0   0   0   4 210 214   5   0   8 255 114   0\n",
      "   0 104 255  18   0   2 183 245  62   0   0   0   0   0   0   0   0   0   0 112 255  68   0   0  10 255 112   0\n",
      "   0  98 255  25   0   0  17 206 246  77   0   0   0   0   0   0   0   0  23 240 173   0   0   0  12 255 109   0\n",
      "   0  68 255  58   0   0   0  12 187 252  98   0   0   0   0   0   0   0 159 246  32   0   0   0  15 255 107   0\n",
      "   0  30 255  96   0   0   0   0   9 179 254 112   0   0   0   0   0  56 254 127   0   0   0   0  17 255 104   0\n",
      "   0   1 245 134   0   0   0   0   0   4 162 255 151   6   0   0   4 203 222   9   0   0   0   0  19 255 102   0\n",
      "   0   0 209 172   0   0   0   0   0   0   1 125 254 227 110   0 148 254  77   0   0   0  41 118 196 255  96   0\n",
      "   0   0 173 236 219 224 170 170 139  99  54  14  62 182 255 194 255 129  14  67 143 220 255 253 199 121  11   0\n",
      "   0   0 105 241 250 244 204 207 240 255 255 255 228 221 239 255 243 237 255 255 243 173  97  22   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  29  70 113 149 153 153 179 155 141 109  67   7   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      "INFO:root:[hunmin log] X_train : (8000, 784)\n",
      "INFO:root:[hunmin log] X_train_cnn : (8000, 28, 28, 1)\n",
      "INFO:root:[hunmin log] Y_train : (8000,)\n",
      "INFO:root:[hunmin log] Y_train_cnn : (8000, 10)\n",
      "INFO:root:[hunmin log] class number : 10\n",
      "INFO:root:[hunmin log] model.summary() :\n",
      "INFO:root:Model: \"sequential\"\n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root:Layer (type)                 Output Shape              Param #   \n",
      "INFO:root:=================================================================\n",
      "INFO:root:conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root:conv2d_1 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root:dropout (Dropout)            (None, 28, 28, 64)        0         \n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root:conv2d_2 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root:max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root:flatten (Flatten)            (None, 12544)             0         \n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root:dense (Dense)                (None, 32)                401440    \n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root:dropout_1 (Dropout)          (None, 32)                0         \n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root:dense_1 (Dense)              (None, 10)                330       \n",
      "INFO:root:=================================================================\n",
      "INFO:root:Total params: 457,514\n",
      "INFO:root:Trainable params: 457,514\n",
      "INFO:root:Non-trainable params: 0\n",
      "INFO:root:_________________________________________________________________\n",
      "INFO:root:[hunmin log] For epoch 1, loss is 1.10.\n",
      "INFO:root:[hunmin log] For epoch 2, loss is 0.62.\n",
      "INFO:root:[hunmin log] For epoch 3, loss is 0.49.\n",
      "INFO:root:[hunmin log] For epoch 4, loss is 0.42.\n",
      "INFO:root:[hunmin log] For epoch 5, loss is 0.36.\n",
      "INFO:root:[hunmin log] For epoch 6, loss is 0.30.\n",
      "INFO:root:[hunmin log] For epoch 7, loss is 0.26.\n",
      "INFO:root:[hunmin log] For epoch 8, loss is 0.22.\n",
      "INFO:root:[hunmin log] For epoch 9, loss is 0.20.\n",
      "INFO:root:[hunmin log] For epoch 10, loss is 0.18.\n",
      "INFO:root:[hunmin log] For epoch 11, loss is 0.18.\n",
      "INFO:root:[hunmin log] For epoch 12, loss is 0.16.\n",
      "INFO:root:[hunmin log] For epoch 13, loss is 0.15.\n",
      "INFO:root:[hunmin log] For epoch 14, loss is 0.15.\n",
      "INFO:root:[hunmin log] For epoch 15, loss is 0.13.\n",
      "INFO:root:[hunmin log] For epoch 16, loss is 0.12.\n",
      "INFO:root:[hunmin log] For epoch 17, loss is 0.13.\n",
      "INFO:root:[hunmin log] For epoch 18, loss is 0.12.\n",
      "INFO:root:[hunmin log] For epoch 19, loss is 0.11.\n",
      "INFO:root:[hunmin log] For epoch 20, loss is 0.11.\n",
      "INFO:root:[hunmin log] loss : [1.104451060295105, 0.6185036301612854, 0.4943051338195801, 0.41626518964767456, 0.35621869564056396, 0.2975179851055145, 0.2581435739994049, 0.22365885972976685, 0.19954073429107666, 0.18089407682418823, 0.17754219472408295, 0.1640264391899109, 0.14566294848918915, 0.14915771782398224, 0.12854114174842834, 0.12083756178617477, 0.12624332308769226, 0.12353385984897614, 0.11234478652477264, 0.1122506856918335]\n",
      "INFO:root:[hunmin log] acc : [0.6362500190734863, 0.8030555844306946, 0.8411111235618591, 0.8606944680213928, 0.8805555701255798, 0.897777795791626, 0.9104166626930237, 0.9204166531562805, 0.9311110973358154, 0.9361110925674438, 0.9390277862548828, 0.9399999976158142, 0.9481944441795349, 0.949999988079071, 0.956250011920929, 0.9547222256660461, 0.9583333134651184, 0.956944465637207, 0.9601389169692993, 0.9626389145851135]\n",
      "INFO:root:[hunmin log] T3QAI_TRAIN_MODEL_PATH : ./meta_data\n",
      "INFO:root:[hunmin log] Files and directories in ./meta_data :\n",
      "INFO:root:[hunmin log] dir_list : ['cnn_model.h5', 'dataset', 'test_dataset', 'Accuracy_Loss.png', 'DownloadFiles']\n",
      "INFO:root:[hunmin log] the finish line of the function [exec_train]\n",
      "INFO:root:[hunmin log] the end line of the function [train]\n",
      "INFO:root:None\n",
      "INFO:root:train finish\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 1min 12s, total: 2min 20s\n",
      "Wall time: 2min 57s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# main() 함수에서 train() 함수 실행\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "personal-stadium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 5 µs, total: 10 µs\n",
      "Wall time: 16.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = init_svc(im, rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "electric-breath",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] df.shape : (1, 1)\n",
      "INFO:root:[hunmin log] type(df) : <class 'pandas.core.frame.DataFrame'>\n",
      "INFO:root:[hunmin log] the end line of the function [transform]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 129 µs, sys: 4.2 ms, total: 4.33 ms\n",
      "Wall time: 3.71 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = transform(df, params, batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tutorial-robert",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the end line of the function [init_model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 121 ms, sys: 7.62 ms, total: 129 ms\n",
      "Wall time: 129 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_info_dict = init_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-transition",
   "metadata": {},
   "source": [
    "### CASE [추론 입력 타입 - 추론 출력 타입] : 총 4가지\n",
    "추론 입력 타입 : DataFrame &rarr; 추론 출력 타입 : Dictionary (1가지)    \n",
    "추론 입력 타입 : File &rarr; 추론 출력 타입 : Dictionary, DownloadFile, DownloadFile의 List (3가지)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-motel",
   "metadata": {},
   "source": [
    "### CASE  [DataFrame - Dictionary]\n",
    "DataFrame 입력에 대한 추론 결과를 딕셔너리(Dictionary) 형태로 리턴(return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "guilty-membrane",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the start line of the function [exec_inference_dataframe]\n",
      "INFO:root:[hunmin log] result : {'inference': ['apple']}\n",
      "INFO:root:[hunmin log] the end line of the function [inference_dataframe]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 219 ms, sys: 16.4 s, total: 16.6 s\n",
      "Wall time: 35.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inference': ['apple']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "inference_dataframe(df, model_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-behavior",
   "metadata": {},
   "source": [
    "### CASE  [File - Dictionary]\n",
    "File 에 대한 추론 결과를 딕셔너리(Dictionary) 형태로 리턴(return)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-advance",
   "metadata": {},
   "source": [
    " 1. 아래 Cell을 실행하면 select data 버튼이 생성됩니다.\n",
    " 2. 생성된 select data 버튼을 눌러 추론할 데이터를 선택하세요.\n",
    " 3. 선택 후 **inference_file(files, model_info_dict)** 을 실행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial-witness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a3df4143994e69a601ce9eac9d4da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='*', button_style='danger', description='select data', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# uploader widget(해당 커널 output의 버튼)에 파일을 업로드 한 뒤 infernece_file으로 추론합니다.\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "alert-bridges",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the start line of the function [exec_inference_file]\n",
      "INFO:root:[hunmin log] inference: my_ant.png\n",
      "INFO:root:[hunmin log] predict: my_ant.png\n",
      "INFO:root:[hunmin log] the end line of the function [inference_file]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 89.3 ms, sys: 3.24 ms, total: 92.5 ms\n",
      "Wall time: 88.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inference': ['ant']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "inference_file(files, model_info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-characteristic",
   "metadata": {},
   "source": [
    "### CASE  [File - DownloadFile / DownloadFile의 List]\n",
    "File 입력에 대한 추론 결과를 DownloadFile 형태 혹은 DownloadFile의 List 형태로 리턴(return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "charming-communications",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:[hunmin log] the start line of the function [exec_inference_file]\n",
      "INFO:root:[hunmin log] inference: my_ant.png\n",
      "INFO:root:[hunmin log] predict: my_ant.png\n",
      "INFO:root:[hunmin log] the end line of the function [inference_file]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'inference': ['ant']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 83 ms, sys: 14.4 ms, total: 97.4 ms\n",
      "Wall time: 92.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# inference의 return을 DownloadFile 으로 할때 실행합니다.\n",
    "inference_result = inference_file(files, model_info_dict)\n",
    "\n",
    "if type(inference_result) == list:\n",
    "    display(*inference_result)\n",
    "else:\n",
    "    display(inference_result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "image_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AIHUNMIN_env",
   "language": "python",
   "name": "aihunmin_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
