{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# í”Œë«í¼ ì—…ë¡œë“œë¥¼ ì‰½ê²Œí•˜ê¸° ìœ„í•œ ë¡œì»¬ ê°œë°œ ì½”ë“œ\n",
    "- T3Q.ai(T3Q.cep + T3Q.dl): ë¹…ë°ì´í„°/ì¸ê³µì§€ëŠ¥ í†µí•© í”Œë«í¼\n",
    "- í”Œë«í¼ ì—…ë¡œë“œë¥¼ ì‰½ê²Œí•˜ê¸° ìœ„í•˜ì—¬ ë¡œì»¬ì—ì„œ ì•„ë˜ì˜ ì½”ë“œ(íŒŒì¼1)ë¥¼ ê°œë°œí•œë‹¤.\n",
    "- íŒŒì¼ 1(íŒŒì¼ëª…): 1_local_platform_image_classification.ipynb\n",
    "\n",
    "### ì „ì²˜ë¦¬ ê°ì²´ ë˜ëŠ” í•™ìŠµëª¨ë¸ ê°ì²´\n",
    "- ì „ì²˜ë¦¬ ê°ì²´ë‚˜ í•™ìŠµëª¨ë¸ ê°ì²´ëŠ” meta_data í´ë” ì•„ë˜ì— ì €ì¥í•œë‹¤.\n",
    "\n",
    "### ë°ì´í„°ì…‹ (í•™ìŠµ ë°ì´í„°/í…ŒìŠ¤íŠ¸ ë°ì´í„°)\n",
    "- í•™ìŠµê³¼ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ë¥¼ ë‚˜ëˆ„ì–´ ê´€ë¦¬í•œë‹¤.\n",
    "- í•™ìŠµ ë°ì´í„°: dataset í´ë” ì•„ë˜ì— ì €ì¥í•˜ê±°ë‚˜ dataset.zip íŒŒì¼ í˜•íƒœë¡œ ì €ì¥í•œë‹¤.\n",
    "- í…ŒìŠ¤íŠ¸ ë°ì´í„°: test_dataset í´ë” ì•„ë˜ì— ì €ì¥í•˜ê±°ë‚˜ test_dataset.zip íŒŒì¼ í˜•íƒœë¡œ ì €ì¥í•œë‹¤.\n",
    "\n",
    "### ë¡œì»¬ ê°œë°œ ì›Œí¬í”Œë¡œìš°(workflow)  \n",
    "- ë¡œì»¬ ê°œë°œ ì›Œí¬í”Œë¡œìš°ë¥¼ ë‹¤ìŒì˜ 4ë‹¨ê³„ë¡œ ë¶„ë¦¬í•œë‹¤.\n",
    "\n",
    "1. ë°ì´í„°ì…‹ ì¤€ë¹„(Data Setup)\n",
    "- ë¡œì»¬ ì €ì¥ì†Œì—ì„œ ì „ì²˜ë¦¬ ë° í•™ìŠµì— í•„ìš”í•œ í•™ìŠµ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•œë‹¤.\n",
    "\n",
    "2. ë°ì´í„° ì „ì²˜ë¦¬(Data Preprocessing)\n",
    "- ë°ì´í„°ì…‹ì˜ ë¶„ì„ ë° ì •ê·œí™”(Normalization)ë“±ì˜ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•œë‹¤.\n",
    "- ë°ì´í„°ë¥¼ ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê°€ê³µí•œë‹¤.\n",
    "- ì¶”ë¡ ê³¼ì •ì—ì„œ í•„ìš”í•œ ê²½ìš°, ë°ì´í„° ì „ì²˜ë¦¬ì— ì‚¬ìš©ëœ ê°ì²´ë¥¼ meta_data í´ë” ì•„ë˜ì— ì €ì¥í•œë‹¤.\n",
    "\n",
    "3. í•™ìŠµ ëª¨ë¸ í›ˆë ¨(Train Model)\n",
    "- ë°ì´í„°ë¥¼ í›ˆë ¨ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê°€ê³µí•œ ë’¤ì— í•™ìŠµ ëª¨ë¸ì„ êµ¬ì„±í•œë‹¤. \n",
    "- í•™ìŠµ ëª¨ë¸ì„ ì¤€ë¹„ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨ì‹œí‚¨ë‹¤.\n",
    "- ì •í™•ë„(Accuracy)ë‚˜ ì†ì‹¤(Loss)ë“± í•™ìŠµ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê²€ì¦í•œë‹¤.\n",
    "- í•™ìŠµ ëª¨ë¸ì˜ ì„±ëŠ¥ ê²€ì¦ í›„, í•™ìŠµ ëª¨ë¸ì„ ë°°í¬í•œë‹¤.\n",
    "- ë°°í¬í•  í•™ìŠµ ëª¨ë¸ì„ meta_data í´ë” ì•„ë˜ì— ì €ì¥í•œë‹¤.\n",
    "\n",
    "4. ì¶”ë¡ (Inference)\n",
    "- ì €ì¥ëœ ì „ì²˜ë¦¬ ê°ì²´ë‚˜ í•™ìŠµ ëª¨ë¸ ê°ì²´ë¥¼ ì¤€ë¹„í•œë‹¤.\n",
    "- ì¶”ë¡ ì— í•„ìš”í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•œë‹¤.\n",
    "- ë°°í¬ëœ í•™ìŠµ ëª¨ë¸ì„ í†µí•´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•œë‹¤. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì¸ê³µì§€ëŠ¥ í†µí•©í”Œë«í¼(T3Q.ai) í”„ë¡œì„¸ìŠ¤ë¥¼ ì´í•´í•˜ê³  ì¸ê³µì§€ëŠ¥ ì‰½ê²Œ í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. ë¨¸ì‹ ëŸ¬ë‹(Machine Learning)ê³¼ ë”¥ëŸ¬ë‹(Deep Learning) í”„ë¡œê·¸ë˜ë° íŒ¨í„´\n",
    "\n",
    "(1) ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°(Dataset Loading)\n",
    "(2) ë°ì´í„° ì „ì²˜ë¦¬(Data Preprocessing)\n",
    "   - ë°ì´í„° ì •ê·œí™”(Normalization)\n",
    "   - í•™ìŠµê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• (Train/Test Data Split) ë“±\n",
    "(3) í•™ìŠµ ëª¨ë¸ êµ¬ì„±(Train Model Build)\n",
    "(4) í•™ìŠµ(Model Training)\n",
    "(5) í•™ìŠµ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦(Model Performance Validation)\n",
    "(6) í•™ìŠµ ëª¨ë¸ ì €ì¥(ë°°í¬) í•˜ê¸°(Model Save)\n",
    "(7) ì¶”ë¡  ë°ì´í„° ì „ì²˜ë¦¬((Data Preprocessing)\n",
    "(8) ì¶”ë¡ (Inference) ë˜ëŠ” ì˜ˆì¸¡(Prediction) \n",
    "(9) ì¶”ë¡  ê²°ê³¼ ë°ì´í„° í›„ì²˜ë¦¬(Data Postprocessing) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ì „ì²˜ë¦¬ ëª¨ë“ˆ ê´€ë¦¬, í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ê´€ë¦¬ í•¨ìˆ˜ ì„¤ëª…\n",
    "\n",
    "1) [preprocess.py] ì „ì²˜ë¦¬ëª¨ë“ˆ ê´€ë¦¬ í•¨ìˆ˜ \n",
    "\n",
    "def process_for_train(pm):\n",
    "    \"\"\"\n",
    "    (1) ì…ë ¥: pm\n",
    "      # pm.source_path: í•™ìŠµí”Œë«í¼/ë°ì´í„°ì…‹ ê´€ë¦¬ ë©”ë‰´ì—ì„œ ì €ì¥í•œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ê²½ë¡œ\n",
    "      # pm.target_path: ì²˜ë¦¬ ì™„ë£Œëœ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ê²½ë¡œ\n",
    "    (2) ì¶œë ¥: None\n",
    "    (3) ì„¤ëª…: \n",
    "      # ë°ì´í„°ì…‹ ê´€ë¦¬ ë©”ë‰´ì—ì„œ ì €ì¥í•œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì„œ í•„ìš”í•œ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰\n",
    "      # ì²˜ë¦¬ ì™„ë£Œëœ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ê¸°ëŠ¥, pm.target_pathì— ì €ì¥\n",
    "      # ì‹¤í–‰í™˜ê²½ ë“±ë¡ì—ì„œ General ì„ íƒ: train() í•¨ìˆ˜ì˜ T3QAI_TRAIN_DATA_PATHë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì „ì²˜ë¦¬ì™€ í•™ìŠµì„ ìˆ˜í–‰ \n",
    "    \"\"\"\n",
    "\n",
    "def init_svc(im, rule):\n",
    "    \"\"\"\n",
    "    (1) ì…ë ¥: im, rule\n",
    "    (2) ì¶œë ¥: ì „ì²˜ë¦¬ ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬(dictionary) ê°ì²´ì— ë‹´ì•„ ë¦¬í„´(return)\n",
    "    (3) ì„¤ëª…: \n",
    "      # process_for_train(pm) í•¨ìˆ˜ì—ì„œ ì €ì¥í•œ ì „ì²˜ë¦¬ ê°ì²´ì™€ ë°ì´í„°ì— ì ìš©ëœ ë£°(rule)ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥\n",
    "      # ì „ì²˜ë¦¬ ê°ì²´, ë£°(rule) ë¶ˆëŸ¬ì˜¤ê¸° ê¸°ëŠ¥ ì—†ì´ ì²˜ë¦¬\n",
    "    \"\"\"\n",
    "\n",
    "    return {}\n",
    "\n",
    "def transform(df, params, batch_id):\n",
    "    \"\"\"\n",
    "    (1) ì…ë ¥: df, params, batch_id\n",
    "      # df: ì¶”ë¡ ëª¨ë¸ê´€ë¦¬ì™€ ì¶”ë¡ APIê´€ë¦¬, ì‹¤ì‹œê°„ ì¶”ë¡ ì„ í†µí•´ ì „ë‹¬ë˜ëŠ” ì¶”ë¡  ì…ë ¥ ë°ì´í„°(dataframe í˜•íƒœ)\n",
    "      # params: init_svc(im, rule) í•¨ìˆ˜ì˜ ë¦¬í„´(return) ê°’ì„ params ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "    (2) ì¶œë ¥: df\n",
    "    (3) ì„¤ëª…: \n",
    "      # df(ì¶”ë¡  ì…ë ¥ ë°ì´í„°)ì— ëŒ€í•œ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•œ í›„ ì „ì²˜ë¦¬ ëœ ë°ì´í„°ë¥¼ inference_dataframe(df, model_info_dict) í•¨ìˆ˜ì˜ \n",
    "      ì…ë ¥ dfì— ì „ë‹¬í•˜ëŠ” ê¸°ëŠ¥\n",
    "      # df(ì¶”ë¡  ì…ë ¥ ë°ì´í„°)ë¥¼ ì „ì²˜ë¦¬ ì—†ì´ inference_dataframe(df, model_info_dict) í•¨ìˆ˜ì˜ ì…ë ¥ dfì— ë¦¬í„´(return)\n",
    "    \"\"\"\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-1) [train.py] í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ê´€ë¦¬ í•¨ìˆ˜\n",
    "\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_TRAIN_OUTPUT_PATH, T3QAI_TRAIN_MODEL_PATH, T3QAI_TRAIN_DATA_PATH\n",
    "\"\"\"\n",
    "(1) ì„¤ëª…:\n",
    "  # t3qai_client : í”Œë«í¼ê³¼ì˜ ì—°ë™ì„ ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆ\n",
    "  # T3QAI_TRAIN_DATA_PATH : pm.target_pathì—ì„œ ì €ì¥í•œ ì „ì²˜ë¦¬ ë°ì´í„° ê²½ë¡œ\n",
    "  # T3QAI_TRAIN_MODEL_PATH : í•™ìŠµ ëª¨ë¸ ì €ì¥ ê²½ë¡œ\n",
    "  # T3QAI_TRAIN_OUTPUT_PATH : í•™ìŠµ ê²°ê³¼ ì¶œë ¥íŒŒì¼ ì €ì¥ ê²½ë¡œ\n",
    "\"\"\"\n",
    "      \n",
    "def train():\n",
    "    \"\"\"\n",
    "    (1) ì…ë ¥: None\n",
    "    (2) ì¶œë ¥: None\n",
    "    (3) ì„¤ëª…: \n",
    "      # pm.target_pathì— ì €ì¥í•œ ë°ì´í„°ë¥¼ T3QAI_TRAIN_DATA_PATH ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "      # ë°ì´í„° ì „ì²˜ë¦¬ì™€ í•™ìŠµ ëª¨ë¸ì„ êµ¬ì„±í•˜ê³  ëª¨ë¸ í•™ìŠµì„ ìˆ˜í–‰\n",
    "      # í•™ìŠµ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê²€ì¦í•˜ê³  ë°°í¬í•  í•™ìŠµ ëª¨ë¸ì„ ì €ì¥\n",
    "      # ì „ì²˜ë¦¬ ê°ì²´ì™€ í•™ìŠµ ëª¨ë¸ ê°ì²´ë¥¼ T3QAI_TRAIN_MODEL_PATH ì— ì €ì¥\n",
    "      # í•™ìŠµ ê²°ê³¼ë¥¼ íŒŒì¼(ì´ë¯¸ì§€, í…ìŠ¤íŠ¸ ë“±) í˜•íƒœë¡œ T3QAI_TRAIN_OUTPUT_PATH ì— ì €ì¥ \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-2) [inference_service.py] í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ê´€ë¦¬ í•¨ìˆ˜\n",
    "\n",
    "import t3qai_client as tc\n",
    "from t3qai_client import T3QAI_INIT_MODEL_PATH\n",
    "\"\"\"\n",
    "(1) ì„¤ëª…:\n",
    "  # T3QAI_INIT_MODEL_PATH : train() í•¨ìˆ˜ì—ì„œ T3QAI_TRAIN_MODEL_PATH ì— ì €ì¥í•œ ì „ì²˜ë¦¬ ê°ì²´ì™€ \n",
    "                            í•™ìŠµ ëª¨ë¸ ê°ì²´ ë“±ì„ ì¶”ë¡  í•˜ê¸° ìœ„í•´ ë¶ˆëŸ¬ì˜¤ëŠ” ê²½ë¡œ\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def init_model():\n",
    "    \"\"\"\n",
    "    (1) ì…ë ¥: None\n",
    "    (2) ì¶œë ¥: ì „ì²˜ë¦¬ ê°ì²´ì™€ í•™ìŠµ ëª¨ë¸ ê°ì²´ ë“±ì„ ë”•ì…”ë„ˆë¦¬(dictionary) ê°ì²´ì— ë‹´ì•„ ë¦¬í„´(return)\n",
    "    (3) ì„¤ëª…: \n",
    "      # T3QAI_TRAIN_MODEL_PATHì— ì €ì¥í•œ ì „ì²˜ë¦¬ ê°ì²´ì™€ í•™ìŠµ ëª¨ë¸ ê°ì²´ ë“±ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥\n",
    "      # ì „ì²˜ë¦¬ ê°ì²´ì™€ í•™ìŠµ ëª¨ë¸ ê°ì²´ ë“±ì„ ë”•ì…”ë„ˆë¦¬(dictionary) í˜•íƒœë¡œ ë¦¬í„´(return)\n",
    "      # ë¦¬í„´(return) ê°’ì„ inference_dataframe(df,model_info_dict), \n",
    "      inference_file(files, model_info_dict) í•¨ìˆ˜ì˜ ì…ë ¥ model_info_dict ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "    \"\"\"\n",
    "    return { **params }\n",
    "\n",
    "def inference_dataframe(df, model_info_dict):\n",
    "    \"\"\"\n",
    "    (1) ì…ë ¥: df, model_info_dict\n",
    "      # df: transform(df, params, batch_id)í•¨ìˆ˜ì˜ ë¦¬í„´(return) ê°’ìœ¼ë¡œ ì „ë‹¬ëœ df, \n",
    "      ì¶”ë¡  ì…ë ¥ ë°ì´í„°(dataframe í˜•íƒœ)\n",
    "      # model_info_dict: init_model() í•¨ìˆ˜ì˜ return ê°’ì„ model_info_dict ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "        ## í•™ìŠµ ëª¨ë¸ ê°ì²´ ì‚¬ìš© ì˜ˆì‹œ       model = model_info_dict.get('model') ë˜ëŠ” \n",
    "                                          model = model_info_dict['model']\n",
    "        ## ì „ì²˜ë¦¬(pca) ê°ì²´ ì‚¬ìš© ì˜ˆì‹œ     pca = model_info_dict.get['pca'] ë˜ëŠ”\n",
    "                                          pca = model_info_dict['pca']\n",
    "                                          \n",
    "    (2) ì¶œë ¥: ì¶”ë¡  ê²°ê³¼ ë”•ì…”ë„ˆë¦¬(dictionary) í˜•íƒœ \n",
    "            result = {'inference': inference_result}\n",
    "\n",
    "                            \n",
    "    (3) ì„¤ëª…: \n",
    "      # ì „ì²˜ë¦¬ ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ df(ì¶”ë¡  ì…ë ¥ ë°ì´í„°)ì— ëŒ€í•œ ì „ì²˜ë¦¬ ìˆ˜í–‰\n",
    "      # ë°°í¬ëœ í•™ìŠµ ëª¨ë¸(model)ì„ ì‚¬ìš©í•˜ì—¬ df(ì¶”ë¡  ì…ë ¥ ë°ì´í„°)ì— ëŒ€í•œ ì¶”ë¡ (ì˜ˆì¸¡)ì„ ìˆ˜í–‰\n",
    "      # ì¶”ë¡  ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬(dictionary) í˜•íƒœë¡œ ë¦¬í„´(return)\n",
    "    \"\"\"\n",
    "    return {**result}\n",
    "\n",
    "def inference_file(files, model_info_dict):\n",
    "    \"\"\"\n",
    "    (1) ì…ë ¥: files, model_info_dict\n",
    "      # files: ì¶”ë¡  í•˜ê³ ì í•˜ëŠ” íŒŒì¼ í˜•íƒœì˜ ì…ë ¥ \n",
    "      # model_info_dict: init_model() í•¨ìˆ˜ì˜ return ê°’ì„ model_info_dict ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "        ## í•™ìŠµ ëª¨ë¸ ê°ì²´ ì‚¬ìš© ì˜ˆì‹œ       model = model_info_dict.get('model') ë˜ëŠ” \n",
    "                                          model = model_info_dict['model']\n",
    "        ## ì „ì²˜ë¦¬(pca) ê°ì²´ ì‚¬ìš© ì˜ˆì‹œ     pca = model_info_dict.get['pca'] ë˜ëŠ”\n",
    "                                          pca = model_info_dict['pca']\n",
    "        \n",
    "    (2) ì¶œë ¥: a. ì¶”ë¡  ê²°ê³¼ ë”•ì…”ë„ˆë¦¬(dictionary) í˜•íƒœ \n",
    "                  result = {'inference': inference_result}\n",
    "              b. ì¶”ë¡  ê²°ê³¼ DownloadFile í˜•íƒœ\n",
    "                  result = DownloadFile(file_path=resultfilepath, file_name=filename1)\n",
    "                  result = DownloadFile(file_obj=resultfileobj, file_name=filename2)\n",
    "              c. ì¶”ë¡  ê²°ê³¼ DownloadFileì˜ listí˜•íƒœ\n",
    "                  result = [DownloadFile(file_path=resultfilepath, file_name=filename), \n",
    "                            DownloadFile(file_obj=resultfileobj, file_name=filename), ...]\n",
    "              \n",
    "    (3) ì„¤ëª…: \n",
    "      # ì „ì²˜ë¦¬ ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ files(ì¶”ë¡  ì…ë ¥ ë°ì´í„°)ì— ëŒ€í•œ ì „ì²˜ë¦¬ ìˆ˜í–‰\n",
    "      # ë°°í¬ëœ í•™ìŠµ ëª¨ë¸(model)ì„ ì‚¬ìš©í•˜ì—¬ files(ì¶”ë¡  ì…ë ¥ ë°ì´í„°)ì— ì¶”ë¡ (ì˜ˆì¸¡)ì„ ìˆ˜í–‰\n",
    "      # ì¶”ë¡  ê²°ê³¼ë¥¼ a.ë”•ì…”ë„ˆë¦¬(dictionary) í˜•íƒœ, b.DownloadFile í˜•íƒœ, c.DownloadFileì˜ list í˜•íƒœë¡œ ë¦¬í„´(return)\n",
    "    \"\"\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess.py\n",
    "\n",
    "from preprocess_sub_seg import exec_process\n",
    "import logging\n",
    "\n",
    "def process_for_train(pm):\n",
    "    exec_process(pm)\n",
    "    logging.info('[hunmin log] the end line of the function [process_for_train]')\n",
    "    \n",
    "def init_svc(im, rule):\n",
    "    return {}\n",
    "\n",
    "def transform(df, params, batch_id):\n",
    "    logging.info('[hunmin log] df.shape : {}'.format(df.shape))\n",
    "    logging.info('[hunmin log] type(df) : {}'.format(type(df)))\n",
    "    logging.info('[hunmin log] the end line of the function [transform]')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# preprocess_sub.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import logging\n",
    "\n",
    "\n",
    "def exec_process(pm):\n",
    "    logging.info('[hunmin log] the start line of the function [exec_process]')\n",
    "\n",
    "    # ì €ì¥ íŒŒì¼ í™•ì¸\n",
    "    list_files_directories(pm.source_path)\n",
    "    \n",
    "    # pm.source_pathì˜ dataset.zip íŒŒì¼ì„\n",
    "    # pm.target_path ê²½ë¡œì— ì••ì¶•í•´ì œ\n",
    "    my_zip_path = os.path.join(pm.source_path,'./meta_data.zip')\n",
    "    extract_zip_file = zipfile.ZipFile(my_zip_path)\n",
    "    extract_zip_file.extractall(pm.target_path)\n",
    "    extract_zip_file.close()\n",
    "    \n",
    "    # ì €ì¥ íŒŒì¼ í™•ì¸\n",
    "    list_files_directories(pm.target_path)\n",
    "\n",
    "    logging.info('[hunmin log] the finish line of the function [exec_process]')\n",
    "\n",
    "# ì €ì¥ íŒŒì¼ í™•ì¸\n",
    "def list_files_directories(path):\n",
    "    # Get the list of all files and directories in current working directory\n",
    "    dir_list = os.listdir(path)\n",
    "    logging.info('[hunmin log] Files and directories in {} :'.format(path))\n",
    "    logging.info('[hunmin log] dir_list : {}'.format(dir_list))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T3QAI_TRAIN_OUTPUT_PATH: /Users/myoungjikim/2024_inisw4_IPRGS_t3q.dl/meta_data\n",
      "T3QAI_TRAIN_MODEL_PATH: /Users/myoungjikim/2024_inisw4_IPRGS_t3q.dl/meta_data\n",
      "T3QAI_TRAIN_DATA_PATH: /Users/myoungjikim/2024_inisw4_IPRGS_t3q.dl/meta_data\n",
      "T3QAI_TEST_DATA_PATH: /Users/myoungjikim/2024_inisw4_IPRGS_t3q.dl/meta_data\n",
      "T3QAI_MODULE_PATH: /Users/myoungjikim/2024_inisw4_IPRGS_t3q.dl/meta_data\n",
      "T3QAI_INIT_MODEL_PATH: /Users/myoungjikim/2024_inisw4_IPRGS_t3q.dl/meta_data\n",
      "df:                                                     0\n",
      "0  iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAA...\n",
      "df.dtypes: 0    object\n",
      "dtype: object\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "íŒŒì¼ íŒ¨ìŠ¤\n",
      "/Users/myoungjikim/2024_inisw4_IPRGS_t3q.dl/.venv/lib/python3.10/site-packages/ultralytics/utils/__init__.py\n",
      "ë£¨íŠ¸\n",
      "/Users/myoungjikim/2024_inisw4_IPRGS_t3q.dl/.venv/lib/python3.10/site-packages/ultralytics\n",
      "ë””í¹íŠ¸ CFG ê²½ë¡œ\n",
      "/Users/myoungjikim/2024_inisw4_IPRGS_t3q.dl/.venv/lib/python3.10/site-packages/ultralytics/cfg/default.yaml\n",
      "ì•¼ë¯ˆ íŒŒì¼ ì½ê¸° ê²°ê³¼1\n",
      "# Ultralytics YOLO ğŸš€, AGPL-3.0 license\n",
      "# Default training settings and hyperparameters for medium-augmentation COCO training\n",
      "\n",
      "task: detect # (str) YOLO task, i.e. detect, segment, classify, pose\n",
      "mode: train # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark\n",
      "\n",
      "# Train settings -------------------------------------------------------------------------------------------------------\n",
      "model: # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml\n",
      "data: # (str, optional) path to data file, i.e. coco8.yaml\n",
      "epochs: 100 # (int) number of epochs to train for\n",
      "time: # (float, optional) number of hours to train for, overrides epochs if supplied\n",
      "patience: 100 # (int) epochs to wait for no observable improvement for early stopping of training\n",
      "batch: 16 # (int) number of images per batch (-1 for AutoBatch)\n",
      "imgsz: 640 # (int | list) input images size as int for train and val modes, or list[h,w] for predict and export modes\n",
      "save: True # (bool) save train checkpoints and predict results\n",
      "save_period: -1 # (int) Save checkpoint every x epochs (disabled if < 1)\n",
      "cache: False # (bool) True/ram, disk or False. Use cache for data loading\n",
      "device: # (int | str | list, optional) device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu\n",
      "workers: 8 # (int) number of worker threads for data loading (per RANK if DDP)\n",
      "project: # (str, optional) project name\n",
      "name: # (str, optional) experiment name, results saved to 'project/name' directory\n",
      "exist_ok: False # (bool) whether to overwrite existing experiment\n",
      "pretrained: True # (bool | str) whether to use a pretrained model (bool) or a model to load weights from (str)\n",
      "optimizer: auto # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]\n",
      "verbose: True # (bool) whether to print verbose output\n",
      "seed: 0 # (int) random seed for reproducibility\n",
      "deterministic: True # (bool) whether to enable deterministic mode\n",
      "single_cls: False # (bool) train multi-class data as single-class\n",
      "rect: False # (bool) rectangular training if mode='train' or rectangular validation if mode='val'\n",
      "cos_lr: False # (bool) use cosine learning rate scheduler\n",
      "close_mosaic: 10 # (int) disable mosaic augmentation for final epochs (0 to disable)\n",
      "resume: False # (bool) resume training from last checkpoint\n",
      "amp: True # (bool) Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check\n",
      "fraction: 1.0 # (float) dataset fraction to train on (default is 1.0, all images in train set)\n",
      "profile: False # (bool) profile ONNX and TensorRT speeds during training for loggers\n",
      "freeze: None # (int | list, optional) freeze first n layers, or freeze list of layer indices during training\n",
      "multi_scale: False # (bool) Whether to use multiscale during training\n",
      "# Segmentation\n",
      "overlap_mask: True # (bool) masks should overlap during training (segment train only)\n",
      "mask_ratio: 4 # (int) mask downsample ratio (segment train only)\n",
      "# Classification\n",
      "dropout: 0.0 # (float) use dropout regularization (classify train only)\n",
      "\n",
      "# Val/Test settings ----------------------------------------------------------------------------------------------------\n",
      "val: True # (bool) validate/test during training\n",
      "split: val # (str) dataset split to use for validation, i.e. 'val', 'test' or 'train'\n",
      "save_json: False # (bool) save results to JSON file\n",
      "save_hybrid: False # (bool) save hybrid version of labels (labels + additional predictions)\n",
      "conf: # (float, optional) object confidence threshold for detection (default 0.25 predict, 0.001 val)\n",
      "iou: 0.7 # (float) intersection over union (IoU) threshold for NMS\n",
      "max_det: 300 # (int) maximum number of detections per image\n",
      "half: False # (bool) use half precision (FP16)\n",
      "dnn: False # (bool) use OpenCV DNN for ONNX inference\n",
      "plots: True # (bool) save plots and images during train/val\n",
      "\n",
      "# Predict settings -----------------------------------------------------------------------------------------------------\n",
      "source: # (str, optional) source directory for images or videos\n",
      "vid_stride: 1 # (int) video frame-rate stride\n",
      "stream_buffer: False # (bool) buffer all streaming frames (True) or return the most recent frame (False)\n",
      "visualize: False # (bool) visualize model features\n",
      "augment: False # (bool) apply image augmentation to prediction sources\n",
      "agnostic_nms: False # (bool) class-agnostic NMS\n",
      "classes: # (int | list[int], optional) filter results by class, i.e. classes=0, or classes=[0,2,3]\n",
      "retina_masks: False # (bool) use high-resolution segmentation masks\n",
      "embed: # (list[int], optional) return feature vectors/embeddings from given layers\n",
      "\n",
      "# Visualize settings ---------------------------------------------------------------------------------------------------\n",
      "show: False # (bool) show predicted images and videos if environment allows\n",
      "save_frames: False # (bool) save predicted individual video frames\n",
      "save_txt: False # (bool) save results as .txt file\n",
      "save_conf: False # (bool) save results with confidence scores\n",
      "save_crop: False # (bool) save cropped images with results\n",
      "show_labels: True # (bool) show prediction labels, i.e. 'person'\n",
      "show_conf: True # (bool) show prediction confidence, i.e. '0.99'\n",
      "show_boxes: True # (bool) show prediction boxes\n",
      "line_width: # (int, optional) line width of the bounding boxes. Scaled to image size if None.\n",
      "\n",
      "# Export settings ------------------------------------------------------------------------------------------------------\n",
      "format: torchscript # (str) format to export to, choices at https://docs.ultralytics.com/modes/export/#export-formats\n",
      "keras: False # (bool) use Kera=s\n",
      "optimize: False # (bool) TorchScript: optimize for mobile\n",
      "int8: False # (bool) CoreML/TF INT8 quantization\n",
      "dynamic: False # (bool) ONNX/TF/TensorRT: dynamic axes\n",
      "simplify: False # (bool) ONNX: simplify model using `onnxslim`\n",
      "opset: # (int, optional) ONNX: opset version\n",
      "workspace: 4 # (int) TensorRT: workspace size (GB)\n",
      "nms: False # (bool) CoreML: add NMS\n",
      "\n",
      "# Hyperparameters ------------------------------------------------------------------------------------------------------\n",
      "lr0: 0.01 # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)\n",
      "lrf: 0.01 # (float) final learning rate (lr0 * lrf)\n",
      "momentum: 0.937 # (float) SGD momentum/Adam beta1\n",
      "weight_decay: 0.0005 # (float) optimizer weight decay 5e-4\n",
      "warmup_epochs: 3.0 # (float) warmup epochs (fractions ok)\n",
      "warmup_momentum: 0.8 # (float) warmup initial momentum\n",
      "warmup_bias_lr: 0.1 # (float) warmup initial bias lr\n",
      "box: 7.5 # (float) box loss gain\n",
      "cls: 0.5 # (float) cls loss gain (scale with pixels)\n",
      "dfl: 1.5 # (float) dfl loss gain\n",
      "pose: 12.0 # (float) pose loss gain\n",
      "kobj: 1.0 # (float) keypoint obj loss gain\n",
      "label_smoothing: 0.0 # (float) label smoothing (fraction)\n",
      "nbs: 64 # (int) nominal batch size\n",
      "hsv_h: 0.015 # (float) image HSV-Hue augmentation (fraction)\n",
      "hsv_s: 0.7 # (float) image HSV-Saturation augmentation (fraction)\n",
      "hsv_v: 0.4 # (float) image HSV-Value augmentation (fraction)\n",
      "degrees: 0.0 # (float) image rotation (+/- deg)\n",
      "translate: 0.1 # (float) image translation (+/- fraction)\n",
      "scale: 0.5 # (float) image scale (+/- gain)\n",
      "shear: 0.0 # (float) image shear (+/- deg)\n",
      "perspective: 0.0 # (float) image perspective (+/- fraction), range 0-0.001\n",
      "flipud: 0.0 # (float) image flip up-down (probability)\n",
      "fliplr: 0.5 # (float) image flip left-right (probability)\n",
      "bgr: 0.0 # (float) image channel BGR (probability)\n",
      "mosaic: 1.0 # (float) image mosaic (probability)\n",
      "mixup: 0.0 # (float) image mixup (probability)\n",
      "copy_paste: 0.0 # (float) segment copy-paste (probability)\n",
      "auto_augment: randaugment # (str) auto augmentation policy for classification (randaugment, autoaugment, augmix)\n",
      "erasing: 0.4 # (float) probability of random erasing during classification training (0-0.9), 0 means no erasing, must be less than 1.0.\n",
      "crop_fraction: 1.0 # (float) image crop fraction for classification (0.1-1), 1.0 means no crop, must be greater than 0.\n",
      "\n",
      "# Custom config.yaml ---------------------------------------------------------------------------------------------------\n",
      "cfg: # (str, optional) for overriding defaults.yaml\n",
      "\n",
      "# Tracker settings ------------------------------------------------------------------------------------------------------\n",
      "tracker: botsort.yaml # (str) tracker type, choices=[botsort.yaml, bytetrack.yaml]\n",
      "\n",
      "ì•¼ë¯ˆ íŒŒì¼ ì½ê¸° ê²°ê³¼\n",
      "{'task': 'detect', 'mode': 'train', 'model': None, 'data': None, 'epochs': 100, 'time': None, 'patience': 100, 'batch': 16, 'imgsz': 640, 'save': True, 'save_period': -1, 'cache': False, 'device': None, 'workers': 8, 'project': None, 'name': None, 'exist_ok': False, 'pretrained': True, 'optimizer': 'auto', 'verbose': True, 'seed': 0, 'deterministic': True, 'single_cls': False, 'rect': False, 'cos_lr': False, 'close_mosaic': 10, 'resume': False, 'amp': True, 'fraction': 1.0, 'profile': False, 'freeze': 'None', 'multi_scale': False, 'overlap_mask': True, 'mask_ratio': 4, 'dropout': 0.0, 'val': True, 'split': 'val', 'save_json': False, 'save_hybrid': False, 'conf': None, 'iou': 0.7, 'max_det': 300, 'half': False, 'dnn': False, 'plots': True, 'source': None, 'vid_stride': 1, 'stream_buffer': False, 'visualize': False, 'augment': False, 'agnostic_nms': False, 'classes': None, 'retina_masks': False, 'embed': None, 'show': False, 'save_frames': False, 'save_txt': False, 'save_conf': False, 'save_crop': False, 'show_labels': True, 'show_conf': True, 'show_boxes': True, 'line_width': None, 'format': 'torchscript', 'keras': False, 'optimize': False, 'int8': False, 'dynamic': False, 'simplify': False, 'opset': None, 'workspace': 4, 'nms': False, 'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'pose': 12.0, 'kobj': 1.0, 'label_smoothing': 0.0, 'nbs': 64, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'bgr': 0.0, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0, 'auto_augment': 'randaugment', 'erasing': 0.4, 'crop_fraction': 1.0, 'cfg': None, 'tracker': 'botsort.yaml'}\n",
      "ì•¼ë¯ˆ íŒŒì¼ ì½ê¸° ê²°ê³¼1\n",
      "settings_version: 0.0.4\n",
      "datasets_dir: /Users/myoungjikim/2024_inisw4_IPRGS_t3q.dl/meta_data/dataset/od\n",
      "weights_dir: weights\n",
      "runs_dir: runs\n",
      "uuid: 816a5e1f1ba3ecf33897edc174448127a005dd2e97fde3f240e1adedc5b407bd\n",
      "sync: true\n",
      "api_key: ''\n",
      "clearml: true\n",
      "comet: true\n",
      "dvc: true\n",
      "hub: true\n",
      "mlflow: true\n",
      "neptune: true\n",
      "raytune: true\n",
      "tensorboard: true\n",
      "wandb: true\n",
      "\n",
      "ì•¼ë¯ˆ íŒŒì¼ ì½ê¸° ê²°ê³¼\n",
      "{'settings_version': '0.0.4', 'datasets_dir': '/Users/myoungjikim/2024_inisw4_IPRGS_t3q.dl/meta_data/dataset/od', 'weights_dir': 'weights', 'runs_dir': 'runs', 'uuid': '816a5e1f1ba3ecf33897edc174448127a005dd2e97fde3f240e1adedc5b407bd', 'sync': True, 'api_key': '', 'clearml': True, 'comet': True, 'dvc': True, 'hub': True, 'mlflow': True, 'neptune': True, 'raytune': True, 'tensorboard': True, 'wandb': True}\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "\n",
    "import logging\n",
    "import train\n",
    "import t3qai_client as tc\n",
    "import train_sub_lp as np\n",
    "import train_sub_od as od\n",
    "\n",
    "\n",
    "def main():\n",
    "    result = None\n",
    "    result_msg = \"success\"\n",
    "    a = tc.t3qai_client()\n",
    "    a.train_start()\n",
    "    try:\n",
    "        train()\n",
    "    except Exception as e:\n",
    "        result = e\n",
    "        result_msg = e\n",
    "        logging.info('error log : {}'.format(e))\n",
    "    a.train_finish(result, result_msg)\n",
    "\n",
    "def train():\n",
    "    logging.info('[hunmin log] the start line of the function [train]')\n",
    "    od.exec_train()\n",
    "    np.exec_train()\n",
    "    logging.info('[hunmin log] the end line of the function [train]')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnsupportedOperation",
     "evalue": "detach",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BytesIO\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minference_service_sub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exec_inference_dataframe\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minference_service_sub_od\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mod_inference\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minference_service_sub_seg\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mseg_inference\u001b[39;00m\n",
      "File \u001b[0;32m~/2024_inisw4_IPRGS_t3q.dl/inference_service_sub.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minference_service_sub_od\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mod_inference\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minference_service_sub_seg\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mseg_inference\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minference_service_sub_lp\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlp_inference\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minference_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marea\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01marea\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexec_inference_dataframe\u001b[39m(df, models_info_dict):\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# SEG MODEL\u001b[39;00m\n",
      "File \u001b[0;32m~/2024_inisw4_IPRGS_t3q.dl/inference_service_sub_lp.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbase64\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minference_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlicense_plate\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlp\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageDraw\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# ëª¨ë¸ í´ë˜ìŠ¤\u001b[39;00m\n",
      "File \u001b[0;32m~/2024_inisw4_IPRGS_t3q.dl/inference_utils/license_plate.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(output, cropped_car, seg_image, car_bbox, reader):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output:\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m: detach"
     ]
    }
   ],
   "source": [
    "# inference_service\n",
    "\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import pandas as pd\n",
    "from inference_service_sub import exec_inference_dataframe\n",
    "import inference_service_sub_od as od_inference\n",
    "import inference_service_sub_seg as seg_inference\n",
    "import inference_service_sub_lp as lp_inference\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "def init_model():\n",
    "    logging.info('[hunmin log] the start line of the function [init_model]')\n",
    "    od_params = od_inference.exec_init_model()\n",
    "    seg_params = seg_inference.exec_init_model()\n",
    "    lp_params = lp_inference.exec_init_model()\n",
    "    logging.info('[hunmin log] the end line of the function [init_model]')\n",
    "    return {\"od_params\":{ **od_params },\"seg_params\":{ **seg_params },\"lp_params\":{ **lp_params }}\n",
    "\n",
    "# ëª¨ë¸ ì¶”ë¡  - dataframe\n",
    "def inference_dataframe(df, models_info_dict):\n",
    "    logging.info(f'[hunmin log] the start line of the function [inference_dataframe]')\n",
    "\n",
    "    final_image, od_result, area_output, license_number, full_od_result, error = exec_inference_dataframe(df, models_info_dict)\n",
    "    response_data = {\n",
    "        'msg': error if error else \"success\",\n",
    "        'image': pil_image_to_base64(final_image) if final_image else None,\n",
    "        'od_result': od_result if od_result else [],\n",
    "        'area': area_output if area_output else {},\n",
    "        'license_number': license_number if license_number else \"\"\n",
    "    }\n",
    "    logging.info(f'[hunmin log] the end line of the function [inference_dataframe].')\n",
    "    return response_data\n",
    "\n",
    "def pil_image_to_base64(image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "# ëª¨ë¸ ì¶”ë¡  - file\n",
    "# def inference_file(files, models_info_dict):\n",
    "#     od_result = od_inference.exec_inference_file(files, models_info_dict['od_params'])\n",
    "#     lp_result = lp_inference.exec_inference_file(files, models_info_dict['lp_params'])\n",
    "#     seg_result = seg_inference.exec_inference_file(files, models_info_dict['seg_params'])\n",
    "#     result = {'od_result':od_result,'seg_result':seg_result,'lp_result':lp_result}\n",
    "#     logging.info('[hunmin log] the end line of the function [inference_file]')\n",
    "#     return result\n",
    "\n",
    "# ì¶”ë¡  ì‹¤í–‰\n",
    "# def main():\n",
    "\n",
    "#     # ëª¨ë¸ ì´ˆê¸°í™”\n",
    "#     models_info_dict = init_model()\n",
    "\n",
    "#     # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "#     image = Image.open('./meta_data/dataset/test/Cars122.jpeg')\n",
    "#     base64_image = pil_image_to_base64(image)\n",
    "#     with open('./temp_base64_image', '+w' ) as file:\n",
    "#         file.write(base64_image)\n",
    "#     image_data = [[base64_image]]\n",
    "#     df = pd.DataFrame(image_data)\n",
    "\n",
    "#     # ëª¨ë¸ ì¶”ë¡  ìš”ì²­\n",
    "#     result = inference_dataframe(df, models_info_dict)\n",
    "\n",
    "#     with open('./temp_result.txt', '+w') as file:\n",
    "#         file.write(str(result))\n",
    "\n",
    "#     # Convert bytes data to an image\n",
    "#     base64_string = result['image']\n",
    "#     decoded_image = base64.b64decode(base64_string)\n",
    "#     result_image = Image.open(BytesIO(decoded_image))\n",
    "\n",
    "#     # Save the image as a PNG file\n",
    "#     result_image.save('final_image.png')\n",
    "\n",
    "#     logging.info('ëª¨ë¸ ì¶”ë¡  ê²°ê³¼')\n",
    "#     logging.info(f'msg: {result[\"msg\"]}')\n",
    "#     logging.info(f'od_result: {result[\"od_result\"]}')\n",
    "#     logging.info(f'area: {result[\"area\"]}')\n",
    "#     logging.info(f'license_number: {result[\"license_number\"]}')\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_service_sub\n",
    "\n",
    "import logging, os\n",
    "from ultralytics import YOLO\n",
    "from t3qai_client import T3QAI_INIT_MODEL_PATH, T3QAI_TRAIN_MODEL_PATH\n",
    "\n",
    "import inference_service_sub_od as od_inference\n",
    "import inference_service_sub_seg as seg_inference\n",
    "import inference_service_sub_lp as lp_inference\n",
    "import meta_data.postprocess_utils.area as area\n",
    "\n",
    "\n",
    "def exec_inference_dataframe(df, models_info_dict):\n",
    "\n",
    "    # SEG MODEL\n",
    "    try:\n",
    "        seg_image, areas, car_bbox, seg_result, seg_error = seg_inference.exec_inference_dataframe(df, models_info_dict['seg_params'])\n",
    "\n",
    "        logging.info(f'seg_model inference result: { {\"seg_image\": type(seg_image), \"areas\": areas, \"car_bbox\":car_bbox, \"seg_result\": seg_result, \"seg_error\":seg_error}}')\n",
    "\n",
    "        if seg_error:\n",
    "            return None, None, None, None, None, seg_error\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, None, None, None, None, str(e) + \" (in SEG)\"\n",
    "\n",
    "    # AREA MODEL\n",
    "    try:\n",
    "        area_output = area.process(areas)\n",
    "        logging.info(f'area process result: { {\"area_ouput\":area_output}}')\n",
    "\n",
    "    except Exception as e:\n",
    "        return seg_image, seg_result, None, None, None, str(e) + \" (in AREA)\"\n",
    "\n",
    "    # LP MODEL\n",
    "    try:\n",
    "        seg_lp_image, license_number, lp_error = lp_inference.exec_inference_dataframe(df, car_bbox, seg_image, models_info_dict['lp_params'])\n",
    "        logging.info(f'LP MODEL process result: { {\"seg_lp_image\":type(seg_lp_image), \"license_number\": license_number, \"lp_error\":lp_error}}')\n",
    "\n",
    "        if lp_error:\n",
    "            return seg_image, seg_result, area_output, None, None, lp_error  + \" (in LP)\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return seg_image, seg_result, area_output, None, None, str(e)  + \" (in LP)\"\n",
    "\n",
    "    # OD MODEL\n",
    "    try:\n",
    "        final_image, od_result, full_od_result, od_error = od_inference.exec_inference_dataframe(df,seg_image,models_info_dict['od_params'])\n",
    "        logging.info(f'OD MODEL process result: { {\"final_image\":type(final_image), \"od_result\": od_result, \"full_od_result\":full_od_result, \"od_error\":od_error}}')\n",
    "\n",
    "        if od_error:\n",
    "            return seg_lp_image, seg_result, area_output, license_number, None, od_error + \" (in OD)\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return seg_lp_image, seg_result, area_output, license_number, None, str(e) + \" (in OD)\"\n",
    "\n",
    "    # result\n",
    "    return final_image, seg_result + od_result, area_output, license_number, full_od_result, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t3q_client\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import base64\n",
    "import pandas as pd\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import FileUpload\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# t3qai_client í´ë˜ìŠ¤: t3qai_client ê°ì²´\n",
    "class t3qai_client:\n",
    "    def train_start(self):\n",
    "        return None\n",
    "\n",
    "    def train_finish(self, result, result_msg):\n",
    "        if result_msg != \"success\":\n",
    "            raise Exception(result_msg)\n",
    "        else:\n",
    "            logging.info(result)\n",
    "            logging.info(\"train finish\")\n",
    "\n",
    "    def train_load_param(self):\n",
    "        '''set_param'''\n",
    "        epoch = 20\n",
    "        batch_size = 16\n",
    "        params = {\"epoch\" : epoch, 'batch_size' : batch_size}\n",
    "        return { **params }\n",
    "\n",
    "class PM:\n",
    "    def __init__(self):\n",
    "        self.source_path = './'\n",
    "        self.target_path = './meta_data'\n",
    "        \n",
    "class UploadFile:\n",
    "    def __init__(self, file, filename):\n",
    "        self.file = file\n",
    "        self.filename = filename\n",
    "\n",
    "def DownloadFile(file_name, file_obj = None, file_path = None):\n",
    "    file_route = './meta_data/DownloadFiles'\n",
    "    os.makedirs(file_route, exist_ok = True)\n",
    "    file_dir = os.path.join(file_route, file_name)\n",
    "    if (file_obj == None) == (file_path == None):\n",
    "        Err_msg = \"[DownloadFile Error]: Only one of the 'file_path' or 'file_obj' arguments is required.\"\n",
    "        Err_msg += f\"{0 if file_obj==None else 2} arguments entered.\"\n",
    "        raise Exception(Err_msg)\n",
    "    elif(file_obj != None):\n",
    "        file_obj.seek(0)\n",
    "        file_read = base64.b64encode(file_obj.read()).decode('utf-8')\n",
    "        binary_file = base64.b64decode(file_read)\n",
    "        with open(file_dir, 'wb') as f:\n",
    "            f.write(binary_file)\n",
    "    elif(file_path != None):\n",
    "        shutil.copyfile(file_path, file_dir)\n",
    "        \n",
    "    return FileLink(file_dir)\n",
    "\n",
    "pm = PM()\n",
    "\n",
    "T3QAI_TRAIN_OUTPUT_PATH = './meta_data'\n",
    "T3QAI_TRAIN_MODEL_PATH = './meta_data'\n",
    "T3QAI_TRAIN_DATA_PATH = './meta_data'\n",
    "T3QAI_TEST_DATA_PATH = './meta_data'\n",
    "T3QAI_MODULE_PATH = './meta_data'\n",
    "T3QAI_INIT_MODEL_PATH = './meta_data'\n",
    "\n",
    "\n",
    "# t3qai_client ê°ì²´\n",
    "tc = t3qai_client()\n",
    "print('T3QAI_TRAIN_OUTPUT_PATH:', T3QAI_TRAIN_OUTPUT_PATH)\n",
    "print('T3QAI_TRAIN_MODEL_PATH:', T3QAI_TRAIN_MODEL_PATH)\n",
    "print('T3QAI_TRAIN_DATA_PATH:', T3QAI_TRAIN_DATA_PATH)\n",
    "print('T3QAI_TEST_DATA_PATH:', T3QAI_TEST_DATA_PATH)\n",
    "print('T3QAI_MODULE_PATH:', T3QAI_MODULE_PATH)\n",
    "print('T3QAI_INIT_MODEL_PATH:', T3QAI_INIT_MODEL_PATH)\n",
    "\n",
    "# init_svc(im, rule) í•¨ìˆ˜ ì…ë ¥\n",
    "im = None\n",
    "rule = None\n",
    "# transform(df, params, batch_id) í•¨ìˆ˜ ì…ë ¥\n",
    "batch_id = 0\n",
    "\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# base64 encoded image - apple.jpg\n",
    "data = [['iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAACySURBVEhL7ZLRDoAgCEWt//9nc8EIEepStvXQeWkyPEKw1FrLbFb+TuWXzichXXb4cAokJR0tH+JFK21G8V6CSqlApMxGelBIsVBHeOOEzZYGdRzpussfL7eIazHPa0wrx0GMdBSiuMbkdINyb5og0gRL3dTbcPtNOpYZveQ2pA1n0hTakF5+hA9Lzd87pNFYLhkvsvT2lMhorndluxkRUuCYbzcp9ROi55+up8sLK1XKBj1wbx3DelAOAAAAAElFTkSuQmCC']]\n",
    "df = pd.DataFrame(data)\n",
    "print('df: ', df)\n",
    "print('df.dtypes:', df.dtypes)\n",
    "\n",
    "# inference_file í•¨ìˆ˜ ì¶”ë¡ \n",
    "files = []\n",
    "\n",
    "uploader = FileUpload(accept='*', multiple=True, description='select data', button_style='danger')\n",
    "def uploader_change(change):\n",
    "    uploader.button_style='success'\n",
    "    count = len(uploader.value)\n",
    "    uploader._counter = count\n",
    "    files.clear()\n",
    "    for file_num in range(count):\n",
    "        temp_data = tempfile.TemporaryFile()\n",
    "        if ipywidgets.__version__[0] == '7':\n",
    "            temp_data.write(list(uploader.value.values())[file_num]['content'])\n",
    "            file = UploadFile(temp_data, pd.DataFrame(list(uploader.value.values())[file_num]).iloc[1,0])\n",
    "        elif int(ipywidgets.__version__[0]) > 7:\n",
    "            temp_data.write(uploader.value[file_num].content)\n",
    "            file = UploadFile(temp_data, uploader.value[file_num].name)\n",
    "        files.append(file)\n",
    "\n",
    "uploader.observe(uploader_change, 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "process_for_train(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "params = init_svc(im, rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = transform(df, params, batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "models_info_dict = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "inference_dataframe(df, models_info_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
